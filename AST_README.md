# 🎤 AST语音转录测试工具使用指南

## 📋 项目概述

AST (Audio Speech Transcription) 语音转录测试工具是一个基于VOSK的实时语音识别测试平台，可以直接使用麦克风测试语音转录效果。

## 🚀 快速开始

### 1. 启动服务

在项目根目录下，打开两个命令行窗口：

**窗口1 - 启动AST API服务器:**
```bash
cd d:\gsxm\timao-douyin-live-manager
python start_ast_test.py
```

**窗口2 - 启动Web服务器:**
```bash
cd d:\gsxm\timao-douyin-live-manager  
python start_web_server.py
```

### 2. 访问测试页面

打开浏览器，访问：
- **测试页面**: http://127.0.0.1:8080/AST_test_page.html
- **API健康检查**: http://127.0.0.1:8001/api/transcription/health
- **API文档**: http://127.0.0.1:8001/docs

## 🎯 使用步骤

### 基本测试流程

1. **检查连接状态** - 页面加载后会自动检查服务器连接
2. **测试麦克风** - 点击"测试麦克风"按钮确保浏览器有音频权限
3. **配置参数** - 调整转录设置：
   - 房间ID: 用于标识测试会话
   - 音频块时长: 1-3秒 (推荐1.0秒)
   - 最小置信度: 0.1-1.0 (推荐0.6)
   - 保存音频: 是否保存音频文件到本地
4. **开始转录** - 点击"开始转录"按钮
5. **说话测试** - 对着麦克风清晰说话
6. **查看结果** - 实时查看转录结果和置信度

### 高级功能

- **实时WebSocket连接** - 获得即时的转录反馈
- **结果导出** - 将转录结果导出为JSON文件
- **统计信息** - 查看识别次数、平均置信度等
- **日志监控** - 实时查看系统运行日志

## 🔧 系统架构

```
AST测试系统架构:

前端测试页面 (8080端口)
    ↓ HTTP API调用
FastAPI服务器 (8001端口)
    ↓ 调用AST模块
AST_module/
    ├── ast_service.py          # 主服务
    ├── vosk_direct_service.py  # VOSK直接集成
    ├── audio_capture.py        # 音频采集
    ├── config.py              # 配置管理
    └── mock_vosk_service.py    # 模拟服务(降级)
```

## 📊 API接口

### REST API
- `POST /api/transcription/start` - 开始转录
- `POST /api/transcription/stop` - 停止转录  
- `GET /api/transcription/status` - 获取状态
- `GET /api/transcription/health` - 健康检查

### WebSocket
- `ws://127.0.0.1:8001/api/transcription/ws` - 实时转录结果推送

## 🎤 语音模型

- **模型类型**: VOSK中文语音识别模型 
- **模型版本**: vosk-model-cn-0.22 (2.04GB)
- **模型路径**: `d:\gsxm\timao-douyin-live-manager\vosk-api\vosk-model-cn-0.22`
- **采样率**: 16kHz
- **音频格式**: 16bit单声道PCM

## ⚙️ 配置参数说明

| 参数 | 默认值 | 说明 |
|------|-------|------|
| chunk_duration | 1.0秒 | 音频块处理时长，越短响应越快但可能影响准确率 |
| min_confidence | 0.6 | 最小置信度阈值，低于此值的结果会被过滤 |
| sample_rate | 16000Hz | 音频采样率，VOSK推荐值 |
| save_audio | false | 是否保存音频文件到audio_logs目录 |

## 🔍 故障排除

### 常见问题

1. **服务器启动失败**
   - 检查端口8001是否被占用
   - 确保Python环境正确安装依赖

2. **麦克风权限被拒绝**
   - 浏览器设置中允许网站访问麦克风
   - 确保有可用的音频输入设备

3. **VOSK模型未找到**
   - 系统会自动降级到模拟服务
   - 模拟服务使用随机中文词汇进行测试

4. **WebSocket连接失败**
   - 检查防火墙设置
   - 确保8001端口可访问

### 性能优化

- **低延迟模式**: chunk_duration设为0.5秒
- **高准确率模式**: chunk_duration设为2.0秒，min_confidence设为0.8
- **调试模式**: 开启save_audio保存音频文件用于分析

## 📝 测试建议

### 测试内容

1. **基础中文词汇** - "你好"、"谢谢"、"再见"
2. **数字和日期** - "一二三四五"、"2024年9月20日"  
3. **长句测试** - "欢迎大家来到我的直播间，今天给大家介绍一个很好的产品"
4. **噪音环境** - 在有背景音的环境下测试
5. **不同音量** - 测试不同说话音量的识别效果

### 评估指标

- **准确率**: 转录文本与实际说话内容的匹配度
- **响应时间**: 从说话到显示结果的延迟
- **置信度**: 系统对识别结果的信心程度
- **稳定性**: 长时间运行的稳定性

## 📈 结果分析

测试完成后，系统提供以下数据：

- **转录次数**: 总共识别的语音段数
- **平均置信度**: 所有识别结果的平均置信度
- **运行时间**: 测试会话的总时长
- **成功率**: 成功识别的比例

## 🔄 后续开发

基于测试结果，可以进一步优化：

1. **模型调优** - 根据具体应用场景训练专用模型
2. **音频预处理** - 添加降噪、音量归一化等功能
3. **多语言支持** - 集成英文或其他语言模型
4. **实时处理** - 优化延迟和内存使用

---

**注意**: 这是一个开发测试工具，用于验证AST模块的功能和性能。在生产环境中部署前，请确保进行充分的测试和优化。