#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çœŸå®è§†é¢‘æ–‡ä»¶éŸ³é¢‘æµ‹è¯•è„šæœ¬
ç”¨äºæµ‹è¯•éŸ³é¢‘é—¨æ§ç®—æ³•åœ¨çœŸå®æŠ–éŸ³ç›´æ’­è§†é¢‘ä¸Šçš„è¡¨ç°
"""

import os
import sys
import numpy as np
import librosa
from pathlib import Path
from datetime import datetime

# å°è¯•å¯¼å…¥moviepy
try:
    from moviepy.editor import VideoFileClip
except ImportError:
    print("è­¦å‘Š: moviepyæœªæ­£ç¡®å®‰è£…ï¼Œå°è¯•ä½¿ç”¨ffmpegç›´æ¥æå–éŸ³é¢‘")
    VideoFileClip = None

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app.services.audio_gate import is_speech_like

class RealVideoAudioTester:
    def __init__(self, video_path):
        """
        åˆå§‹åŒ–çœŸå®è§†é¢‘éŸ³é¢‘æµ‹è¯•å™¨
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        """
        self.video_path = video_path
        self.results = []
        
    def extract_audio_from_video(self, output_path=None):
        """
        ä»è§†é¢‘æ–‡ä»¶ä¸­æå–éŸ³é¢‘
        
        Args:
            output_path: è¾“å‡ºéŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ
            
        Returns:
            str: æå–çš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        """
        print(f"æ­£åœ¨ä»è§†é¢‘æ–‡ä»¶æå–éŸ³é¢‘: {self.video_path}")
        
        if not os.path.exists(self.video_path):
            raise FileNotFoundError(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {self.video_path}")
        
        # ç”Ÿæˆè¾“å‡ºè·¯å¾„
        if output_path is None:
            video_name = Path(self.video_path).stem
            output_path = f"extracted_audio_{video_name}.wav"
        
        try:
            # ä½¿ç”¨moviepyæå–éŸ³é¢‘
            if VideoFileClip is None:
                raise ImportError("MoviePy not available")
                
            video = VideoFileClip(self.video_path)
            audio = video.audio
            
            if audio is None:
                raise ValueError("è§†é¢‘æ–‡ä»¶ä¸­æ²¡æœ‰éŸ³é¢‘è½¨é“")
            
            # å¯¼å‡ºéŸ³é¢‘ä¸ºWAVæ ¼å¼
            audio.write_audiofile(output_path, verbose=False, logger=None)
            
            # æ¸…ç†èµ„æº
            audio.close()
            video.close()
            
            print(f"éŸ³é¢‘æå–å®Œæˆ: {output_path}")
            return output_path
            
        except Exception as e:
            print(f"MoviePyéŸ³é¢‘æå–å¤±è´¥: {str(e)}")
            # å°è¯•ä½¿ç”¨ffmpegç›´æ¥æå–
            return self._extract_audio_with_ffmpeg(output_path)
    
    def _extract_audio_with_ffmpeg(self, output_path):
        """
        ä½¿ç”¨ffmpegç›´æ¥æå–éŸ³é¢‘
        """
        import subprocess
        
        try:
            print("å°è¯•ä½¿ç”¨ffmpegç›´æ¥æå–éŸ³é¢‘...")
            cmd = [
                'ffmpeg', '-i', self.video_path, 
                '-vn', '-acodec', 'pcm_s16le', 
                '-ar', '44100', '-ac', '2', 
                '-y', output_path
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                print(f"ffmpegéŸ³é¢‘æå–å®Œæˆ: {output_path}")
                return output_path
            else:
                raise Exception(f"ffmpegé”™è¯¯: {result.stderr}")
                
        except FileNotFoundError:
            print("é”™è¯¯: æœªæ‰¾åˆ°ffmpegï¼Œè¯·å®‰è£…ffmpegæˆ–moviepy")
            raise
        except Exception as e:
            print(f"ffmpegéŸ³é¢‘æå–å¤±è´¥: {str(e)}")
            raise
    
    def analyze_audio_segments(self, audio_path, segment_duration=2.0):
        """
        åˆ†æéŸ³é¢‘ç‰‡æ®µ
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            segment_duration: æ¯ä¸ªç‰‡æ®µçš„æ—¶é•¿ï¼ˆç§’ï¼‰
            
        Returns:
            list: åˆ†æç»“æœåˆ—è¡¨
        """
        print(f"æ­£åœ¨åˆ†æéŸ³é¢‘æ–‡ä»¶: {audio_path}")
        
        # åŠ è½½éŸ³é¢‘
        y, sr = librosa.load(audio_path, sr=None)
        total_duration = len(y) / sr
        
        print(f"éŸ³é¢‘æ€»æ—¶é•¿: {total_duration:.2f}ç§’")
        print(f"é‡‡æ ·ç‡: {sr}Hz")
        
        # åˆ†æ®µåˆ†æ
        segment_samples = int(segment_duration * sr)
        num_segments = int(np.ceil(len(y) / segment_samples))
        
        results = []
        
        for i in range(num_segments):
            start_idx = i * segment_samples
            end_idx = min((i + 1) * segment_samples, len(y))
            segment = y[start_idx:end_idx]
            
            # è·³è¿‡å¤ªçŸ­çš„ç‰‡æ®µ
            if len(segment) < sr * 0.5:  # è‡³å°‘0.5ç§’
                continue
            
            start_time = start_idx / sr
            end_time = end_idx / sr
            
            print(f"åˆ†æç‰‡æ®µ {i+1}/{num_segments}: {start_time:.1f}s - {end_time:.1f}s")
            
            # ä½¿ç”¨éŸ³é¢‘é—¨æ§ç®—æ³•åˆ†æ
            try:
                # è½¬æ¢ä¸ºPCM16æ ¼å¼
                pcm16_data = (segment * 32767).astype(np.int16).tobytes()
                is_speech, details = is_speech_like(pcm16_data, sr)
                
                # è®¡ç®—é¢å¤–çš„éŸ³é¢‘ç‰¹å¾
                rms = np.sqrt(np.mean(segment**2))
                spectral_centroid = librosa.feature.spectral_centroid(y=segment, sr=sr)[0].mean()
                zero_crossing_rate = librosa.feature.zero_crossing_rate(segment)[0].mean()
                
                result = {
                    'segment_id': i + 1,
                    'start_time': start_time,
                    'end_time': end_time,
                    'duration': end_time - start_time,
                    'is_speech': is_speech,
                    'details': details,
                    'rms': rms,
                    'spectral_centroid': spectral_centroid,
                    'zero_crossing_rate': zero_crossing_rate,
                    'audio_data': segment  # ä¿å­˜éŸ³é¢‘æ•°æ®ç”¨äºè¿›ä¸€æ­¥åˆ†æ
                }
                
                results.append(result)
                
                # æ‰“å°å®æ—¶ç»“æœ
                status = "âœ… è¯­éŸ³" if is_speech else "âŒ éè¯­éŸ³/éŸ³ä¹"
                print(f"  ç»“æœ: {status} | RMS: {rms:.4f} | é¢‘è°±è´¨å¿ƒ: {spectral_centroid:.1f}Hz")
                
            except Exception as e:
                print(f"  åˆ†æå¤±è´¥: {str(e)}")
                continue
        
        self.results = results
        return results
    
    def generate_detailed_report(self):
        """
        ç”Ÿæˆè¯¦ç»†çš„åˆ†ææŠ¥å‘Š
        """
        if not self.results:
            print("æ²¡æœ‰åˆ†æç»“æœå¯ç”¨äºç”ŸæˆæŠ¥å‘Š")
            return
        
        print("\n" + "="*80)
        print("çœŸå®è§†é¢‘éŸ³é¢‘åˆ†æè¯¦ç»†æŠ¥å‘Š")
        print("="*80)
        
        # åŸºæœ¬ç»Ÿè®¡
        total_segments = len(self.results)
        speech_segments = sum(1 for r in self.results if r['is_speech'])
        non_speech_segments = total_segments - speech_segments
        
        total_duration = sum(r['duration'] for r in self.results)
        speech_duration = sum(r['duration'] for r in self.results if r['is_speech'])
        non_speech_duration = total_duration - speech_duration
        
        print(f"\nğŸ“Š åŸºæœ¬ç»Ÿè®¡:")
        print(f"  æ€»ç‰‡æ®µæ•°: {total_segments}")
        print(f"  è¯­éŸ³ç‰‡æ®µ: {speech_segments} ({speech_segments/total_segments*100:.1f}%)")
        print(f"  éè¯­éŸ³ç‰‡æ®µ: {non_speech_segments} ({non_speech_segments/total_segments*100:.1f}%)")
        print(f"  æ€»æ—¶é•¿: {total_duration:.1f}ç§’")
        print(f"  è¯­éŸ³æ—¶é•¿: {speech_duration:.1f}ç§’ ({speech_duration/total_duration*100:.1f}%)")
        print(f"  éè¯­éŸ³æ—¶é•¿: {non_speech_duration:.1f}ç§’ ({non_speech_duration/total_duration*100:.1f}%)")
        
        # éŸ³é¢‘ç‰¹å¾ç»Ÿè®¡
        speech_results = [r for r in self.results if r['is_speech']]
        non_speech_results = [r for r in self.results if not r['is_speech']]
        
        print(f"\nğŸµ éŸ³é¢‘ç‰¹å¾å¯¹æ¯”:")
        if speech_results:
            speech_rms_avg = np.mean([r['rms'] for r in speech_results])
            speech_centroid_avg = np.mean([r['spectral_centroid'] for r in speech_results])
            speech_zcr_avg = np.mean([r['zero_crossing_rate'] for r in speech_results])
            
            print(f"  è¯­éŸ³ç‰‡æ®µå¹³å‡ç‰¹å¾:")
            print(f"    RMS: {speech_rms_avg:.4f}")
            print(f"    é¢‘è°±è´¨å¿ƒ: {speech_centroid_avg:.1f}Hz")
            print(f"    è¿‡é›¶ç‡: {speech_zcr_avg:.4f}")
        
        if non_speech_results:
            non_speech_rms_avg = np.mean([r['rms'] for r in non_speech_results])
            non_speech_centroid_avg = np.mean([r['spectral_centroid'] for r in non_speech_results])
            non_speech_zcr_avg = np.mean([r['zero_crossing_rate'] for r in non_speech_results])
            
            print(f"  éè¯­éŸ³ç‰‡æ®µå¹³å‡ç‰¹å¾:")
            print(f"    RMS: {non_speech_rms_avg:.4f}")
            print(f"    é¢‘è°±è´¨å¿ƒ: {non_speech_centroid_avg:.1f}Hz")
            print(f"    è¿‡é›¶ç‡: {non_speech_zcr_avg:.4f}")
        
        # æ—¶é—´çº¿åˆ†æ
        print(f"\nâ° æ—¶é—´çº¿åˆ†æ:")
        print("  æ—¶é—´æ®µ | çŠ¶æ€ | RMS | é¢‘è°±è´¨å¿ƒ | è¿‡é›¶ç‡")
        print("  " + "-"*60)
        
        for result in self.results[:20]:  # æ˜¾ç¤ºå‰20ä¸ªç‰‡æ®µ
            status = "è¯­éŸ³" if result['is_speech'] else "éè¯­éŸ³"
            print(f"  {result['start_time']:5.1f}s-{result['end_time']:5.1f}s | {status:4s} | "
                  f"{result['rms']:6.4f} | {result['spectral_centroid']:8.1f}Hz | {result['zero_crossing_rate']:6.4f}")
        
        if len(self.results) > 20:
            print(f"  ... (è¿˜æœ‰ {len(self.results)-20} ä¸ªç‰‡æ®µ)")
        
        # è¿ç»­æ€§åˆ†æ
        print(f"\nğŸ”„ è¿ç»­æ€§åˆ†æ:")
        speech_blocks = []
        non_speech_blocks = []
        
        current_block = None
        for result in self.results:
            if current_block is None:
                current_block = {
                    'type': 'speech' if result['is_speech'] else 'non_speech',
                    'start_time': result['start_time'],
                    'end_time': result['end_time'],
                    'count': 1
                }
            elif (result['is_speech'] and current_block['type'] == 'speech') or \
                 (not result['is_speech'] and current_block['type'] == 'non_speech'):
                # ç»§ç»­å½“å‰å—
                current_block['end_time'] = result['end_time']
                current_block['count'] += 1
            else:
                # å¼€å§‹æ–°å—
                if current_block['type'] == 'speech':
                    speech_blocks.append(current_block)
                else:
                    non_speech_blocks.append(current_block)
                
                current_block = {
                    'type': 'speech' if result['is_speech'] else 'non_speech',
                    'start_time': result['start_time'],
                    'end_time': result['end_time'],
                    'count': 1
                }
        
        # æ·»åŠ æœ€åä¸€ä¸ªå—
        if current_block:
            if current_block['type'] == 'speech':
                speech_blocks.append(current_block)
            else:
                non_speech_blocks.append(current_block)
        
        print(f"  è¿ç»­è¯­éŸ³å—æ•°: {len(speech_blocks)}")
        if speech_blocks:
            avg_speech_duration = np.mean([b['end_time'] - b['start_time'] for b in speech_blocks])
            max_speech_duration = max([b['end_time'] - b['start_time'] for b in speech_blocks])
            print(f"    å¹³å‡æŒç»­æ—¶é—´: {avg_speech_duration:.1f}ç§’")
            print(f"    æœ€é•¿æŒç»­æ—¶é—´: {max_speech_duration:.1f}ç§’")
        
        print(f"  è¿ç»­éè¯­éŸ³å—æ•°: {len(non_speech_blocks)}")
        if non_speech_blocks:
            avg_non_speech_duration = np.mean([b['end_time'] - b['start_time'] for b in non_speech_blocks])
            max_non_speech_duration = max([b['end_time'] - b['start_time'] for b in non_speech_blocks])
            print(f"    å¹³å‡æŒç»­æ—¶é—´: {avg_non_speech_duration:.1f}ç§’")
            print(f"    æœ€é•¿æŒç»­æ—¶é—´: {max_non_speech_duration:.1f}ç§’")
        
        # ç®—æ³•æ€§èƒ½è¯„ä¼°
        print(f"\nâš¡ ç®—æ³•æ€§èƒ½è¯„ä¼°:")
        print("  åŸºäºçœŸå®æŠ–éŸ³ç›´æ’­è§†é¢‘çš„æµ‹è¯•ç»“æœ:")
        
        if speech_duration > 0 and non_speech_duration > 0:
            print(f"  âœ… èƒ½å¤ŸåŒºåˆ†è¯­éŸ³å’Œéè¯­éŸ³å†…å®¹")
            print(f"  ğŸ“ˆ è¯­éŸ³æ£€æµ‹è¦†ç›–ç‡: {speech_duration/total_duration*100:.1f}%")
            
            # åˆ¤æ–­æ˜¯å¦è¿‡åº¦è¿‡æ»¤
            if speech_duration / total_duration < 0.1:
                print(f"  âš ï¸  è­¦å‘Š: è¯­éŸ³æ£€æµ‹ç‡è¾ƒä½ï¼Œå¯èƒ½å­˜åœ¨è¿‡åº¦è¿‡æ»¤")
            elif speech_duration / total_duration > 0.8:
                print(f"  âš ï¸  è­¦å‘Š: è¯­éŸ³æ£€æµ‹ç‡è¾ƒé«˜ï¼Œå¯èƒ½å­˜åœ¨æ¬ è¿‡æ»¤")
            else:
                print(f"  âœ… è¯­éŸ³æ£€æµ‹ç‡é€‚ä¸­ï¼Œç®—æ³•è¡¨ç°è‰¯å¥½")
        
        print(f"\nğŸ¯ æ€»ä½“è¯„ä¼°:")
        if 0.2 <= speech_duration / total_duration <= 0.7:
            print("  âœ… ä¼˜ç§€ - ç®—æ³•åœ¨çœŸå®è§†é¢‘ä¸Šè¡¨ç°è‰¯å¥½")
        elif 0.1 <= speech_duration / total_duration < 0.2 or 0.7 < speech_duration / total_duration <= 0.9:
            print("  âš ï¸  è‰¯å¥½ - ç®—æ³•åŸºæœ¬å¯ç”¨ï¼Œä½†å¯èƒ½éœ€è¦å¾®è°ƒ")
        else:
            print("  âŒ éœ€è¦æ”¹è¿› - ç®—æ³•åœ¨çœŸå®è§†é¢‘ä¸Šè¡¨ç°ä¸ä½³")
    
    def save_results_to_file(self, output_file=None):
        """
        ä¿å­˜åˆ†æç»“æœåˆ°æ–‡ä»¶
        
        Args:
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        if output_file is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = f"real_video_audio_analysis_{timestamp}.txt"
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("çœŸå®è§†é¢‘éŸ³é¢‘åˆ†æç»“æœ\n")
            f.write("="*50 + "\n")
            f.write(f"è§†é¢‘æ–‡ä»¶: {self.video_path}\n")
            f.write(f"åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            for result in self.results:
                status = "è¯­éŸ³" if result['is_speech'] else "éè¯­éŸ³"
                f.write(f"ç‰‡æ®µ {result['segment_id']}: {result['start_time']:.1f}s-{result['end_time']:.1f}s | "
                       f"{status} | RMS: {result['rms']:.4f} | "
                       f"é¢‘è°±è´¨å¿ƒ: {result['spectral_centroid']:.1f}Hz\n")
        
        print(f"åˆ†æç»“æœå·²ä¿å­˜åˆ°: {output_file}")

def main():
    """ä¸»å‡½æ•°"""
    # è§†é¢‘æ–‡ä»¶è·¯å¾„
    video_path = r"d:\gsxm\timao-douyin-live-manager\StreamCap\downloads\æŠ–éŸ³\@é‡‘\@é‡‘_2025-10-27_18-15-18_000.mp4"
    
    print("="*80)
    print("çœŸå®è§†é¢‘éŸ³é¢‘æµ‹è¯•ç¨‹åº")
    print("="*80)
    
    try:
        # åˆ›å»ºæµ‹è¯•å™¨
        tester = RealVideoAudioTester(video_path)
        
        # æå–éŸ³é¢‘
        audio_path = tester.extract_audio_from_video()
        
        # åˆ†æéŸ³é¢‘
        results = tester.analyze_audio_segments(audio_path, segment_duration=2.0)
        
        # ç”ŸæˆæŠ¥å‘Š
        tester.generate_detailed_report()
        
        # ä¿å­˜ç»“æœ
        tester.save_results_to_file()
        
        # æ¸…ç†ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
        if os.path.exists(audio_path):
            os.remove(audio_path)
            print(f"å·²æ¸…ç†ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶: {audio_path}")
        
        print("\nâœ… æµ‹è¯•å®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()