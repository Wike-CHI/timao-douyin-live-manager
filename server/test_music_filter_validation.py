#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
éŸ³ä¹è¿‡æ»¤æ•ˆæœéªŒè¯æµ‹è¯•
ä¸“é—¨æµ‹è¯•è‹±æ–‡æ­Œæ›²è¿‡æ»¤èƒ½åŠ›
"""

import numpy as np
import time
import sys
import os

# è®¾ç½®ç¼–ç 
if sys.platform == "win32":
    os.system("chcp 65001 > nul")

from app.services.audio_gate import is_speech_like

def generate_english_song_audio(duration=1.0, sr=16000):
    """ç”Ÿæˆæ¨¡æ‹Ÿè‹±æ–‡æ­Œæ›²çš„éŸ³é¢‘"""
    t = np.linspace(0, duration, int(sr * duration))
    
    # è‹±æ–‡æ­Œæ›²ç‰¹å¾ï¼š
    # 1. å¼ºè°æ³¢ç»“æ„ï¼ˆåŸºé¢‘ + å¤šæ¬¡è°æ³¢ï¼‰
    # 2. è§„å¾‹èŠ‚æ‹
    # 3. è¾ƒå®½çš„é¢‘ç‡èŒƒå›´
    # 4. æŒç»­çš„éŸ³è°ƒ
    
    # åŸºé¢‘ (C4 = 261.63 Hz)
    fundamental = 261.63
    
    # æ„å»ºè°æ³¢ç»“æ„ï¼ˆéŸ³ä¹çš„å…¸å‹ç‰¹å¾ï¼‰
    audio = np.zeros_like(t)
    harmonics = [1, 2, 3, 4, 5, 6]  # 1-6æ¬¡è°æ³¢
    amplitudes = [1.0, 0.7, 0.5, 0.3, 0.2, 0.1]  # é€’å‡çš„å¹…åº¦
    
    for h, amp in zip(harmonics, amplitudes):
        freq = fundamental * h
        if freq < sr / 2:  # é¿å…æ··å 
            audio += amp * np.sin(2 * np.pi * freq * t)
    
    # æ·»åŠ èŠ‚æ‹ï¼ˆ120 BPMï¼‰
    beat_freq = 2.0  # 2 Hz = 120 BPM
    beat_envelope = 0.5 + 0.5 * np.sin(2 * np.pi * beat_freq * t)
    audio *= beat_envelope
    
    # æ·»åŠ è½»å¾®çš„éšæœºå˜åŒ–ï¼ˆæ¨¡æ‹Ÿæ­Œå£°çš„è‡ªç„¶å˜åŒ–ï¼‰
    vibrato = 0.1 * np.sin(2 * np.pi * 5 * t)  # 5Hzé¢¤éŸ³
    audio *= (1 + vibrato)
    
    # å½’ä¸€åŒ–å¹¶è½¬æ¢ä¸º16ä½PCM
    audio = audio / np.max(np.abs(audio)) * 0.3  # æ§åˆ¶éŸ³é‡
    return (audio * 32768).astype(np.int16).tobytes()

def generate_chinese_speech_audio(duration=1.0, sr=16000):
    """ç”Ÿæˆæ¨¡æ‹Ÿä¸­æ–‡è¯­éŸ³çš„éŸ³é¢‘"""
    t = np.linspace(0, duration, int(sr * duration))
    
    # ä¸­æ–‡è¯­éŸ³ç‰¹å¾ï¼š
    # 1. äººå£°é¢‘å¸¦é›†ä¸­ï¼ˆ300-3400Hzï¼‰
    # 2. è°ƒåˆ¶å˜åŒ–ï¼ˆè¯­éŸ³èŠ‚å¾‹ï¼‰
    # 3. è¾ƒä½çš„è°æ³¢å¼ºåº¦
    # 4. ä¸è§„å¾‹çš„åŒ…ç»œå˜åŒ–
    
    # åŸºé¢‘åœ¨äººå£°èŒƒå›´å†…
    f0 = 150  # ç”·å£°åŸºé¢‘
    
    # æ„å»ºè¯­éŸ³è°æ³¢ï¼ˆè¾ƒå¼±çš„è°æ³¢ç»“æ„ï¼‰
    audio = np.zeros_like(t)
    harmonics = [1, 2, 3]  # åªæœ‰å‰3æ¬¡è°æ³¢
    amplitudes = [1.0, 0.3, 0.1]  # å¿«é€Ÿè¡°å‡
    
    for h, amp in zip(harmonics, amplitudes):
        freq = f0 * h
        # æ·»åŠ é¢‘ç‡è°ƒåˆ¶ï¼ˆæ¨¡æ‹Ÿè¯­è°ƒå˜åŒ–ï¼‰
        freq_mod = freq * (1 + 0.1 * np.sin(2 * np.pi * 3 * t))
        audio += amp * np.sin(2 * np.pi * freq_mod * t)
    
    # æ·»åŠ è¯­éŸ³åŒ…ç»œï¼ˆä¸è§„å¾‹å˜åŒ–ï¼‰
    envelope = np.abs(np.sin(2 * np.pi * 4 * t)) ** 0.5
    envelope *= (1 + 0.3 * np.random.randn(len(t)))  # æ·»åŠ éšæœºå˜åŒ–
    envelope = np.clip(envelope, 0, 1)
    audio *= envelope
    
    # æ·»åŠ è½»å¾®å™ªå£°ï¼ˆæ¨¡æ‹Ÿè¯­éŸ³çš„å™ªå£°æˆåˆ†ï¼‰
    noise = 0.05 * np.random.randn(len(t))
    audio += noise
    
    # å½’ä¸€åŒ–å¹¶è½¬æ¢ä¸º16ä½PCM
    audio = audio / np.max(np.abs(audio)) * 0.2
    return (audio * 32768).astype(np.int16).tobytes()

def test_music_vs_speech_detection():
    """æµ‹è¯•éŸ³ä¹ä¸è¯­éŸ³çš„åŒºåˆ†èƒ½åŠ›"""
    print("=" * 60)
    print("éŸ³ä¹ä¸è¯­éŸ³åŒºåˆ†èƒ½åŠ›æµ‹è¯•")
    print("=" * 60)
    
    # æµ‹è¯•1: è‹±æ–‡æ­Œæ›²ï¼ˆåº”è¯¥è¢«è¿‡æ»¤ï¼‰
    print("\n1. æµ‹è¯•è‹±æ–‡æ­Œæ›²ï¼ˆåº”è¯¥è¢«è¿‡æ»¤ï¼‰:")
    english_song = generate_english_song_audio()
    result, details = is_speech_like(english_song, 16000)
    
    print(f"   ç»“æœ: {'[å¤±è´¥ - è¯¯è¯†åˆ«ä¸ºè¯­éŸ³]' if result else '[æˆåŠŸ - æ­£ç¡®è¿‡æ»¤]'}")
    print(f"   è¯¦ç»†ä¿¡æ¯:")
    print(f"     - RMS: {details.get('rms', 0):.4f}")
    print(f"     - äººå£°é¢‘å¸¦æ¯”: {details.get('r_voice', 0):.3f}")
    print(f"     - é¢‘è°±è´¨å¿ƒ: {details.get('centroid', 0):.1f} Hz")
    print(f"     - è°ƒåˆ¶èƒ½é‡: {details.get('mod', 0):.3f}")
    print(f"     - é¢‘è°±å¹³å¦åº¦: {details.get('flatness', 0):.3f}")
    print(f"     - è°æ³¢å¼ºåº¦: {details.get('harmonic_strength', 0):.3f}")
    print(f"     - èŠ‚æ‹è§„å¾‹æ€§: {details.get('beat_regularity', 0):.3f}")
    print(f"     - éŸ³ä¹ç‰¹å¾: {details.get('music_like', False)}")
    print(f"     - è§„å¾‹èŠ‚æ‹: {details.get('regular_beat', False)}")
    
    # æµ‹è¯•2: ä¸­æ–‡è¯­éŸ³ï¼ˆåº”è¯¥é€šè¿‡ï¼‰
    print("\n2. æµ‹è¯•ä¸­æ–‡è¯­éŸ³ï¼ˆåº”è¯¥é€šè¿‡ï¼‰:")
    chinese_speech = generate_chinese_speech_audio()
    result2, details2 = is_speech_like(chinese_speech, 16000)
    
    print(f"   ç»“æœ: {'[æˆåŠŸ - æ­£ç¡®è¯†åˆ«ä¸ºè¯­éŸ³]' if result2 else '[å¤±è´¥ - è¯¯è¿‡æ»¤]'}")
    print(f"   è¯¦ç»†ä¿¡æ¯:")
    print(f"     - RMS: {details2.get('rms', 0):.4f}")
    print(f"     - äººå£°é¢‘å¸¦æ¯”: {details2.get('r_voice', 0):.3f}")
    print(f"     - é¢‘è°±è´¨å¿ƒ: {details2.get('centroid', 0):.1f} Hz")
    print(f"     - è°ƒåˆ¶èƒ½é‡: {details2.get('mod', 0):.3f}")
    print(f"     - é¢‘è°±å¹³å¦åº¦: {details2.get('flatness', 0):.3f}")
    print(f"     - è°æ³¢å¼ºåº¦: {details2.get('harmonic_strength', 0):.3f}")
    print(f"     - èŠ‚æ‹è§„å¾‹æ€§: {details2.get('beat_regularity', 0):.3f}")
    print(f"     - éŸ³ä¹ç‰¹å¾: {details2.get('music_like', False)}")
    print(f"     - è§„å¾‹èŠ‚æ‹: {details2.get('regular_beat', False)}")
    
    return not result and result2  # éŸ³ä¹è¢«è¿‡æ»¤ä¸”è¯­éŸ³é€šè¿‡

def test_various_music_types():
    """æµ‹è¯•å„ç§ç±»å‹çš„éŸ³ä¹è¿‡æ»¤æ•ˆæœ"""
    print("\n" + "=" * 60)
    print("å„ç§éŸ³ä¹ç±»å‹è¿‡æ»¤æµ‹è¯•")
    print("=" * 60)
    
    test_cases = [
        ("æµè¡ŒéŸ³ä¹", 440.0, [1, 2, 3, 4, 5], [1.0, 0.8, 0.6, 0.4, 0.2]),
        ("å¤å…¸éŸ³ä¹", 523.25, [1, 2, 3, 4, 5, 6, 7, 8], [1.0, 0.7, 0.5, 0.4, 0.3, 0.2, 0.15, 0.1]),
        ("ç”µå­éŸ³ä¹", 220.0, [1, 3, 5, 7], [1.0, 0.9, 0.8, 0.7]),
        ("æ‘‡æ»šéŸ³ä¹", 329.63, [1, 2, 4, 8], [1.0, 0.6, 0.4, 0.2]),
    ]
    
    success_count = 0
    total_count = len(test_cases)
    
    for name, fundamental, harmonics, amplitudes in test_cases:
        print(f"\næµ‹è¯• {name}:")
        
        # ç”ŸæˆéŸ³ä¹éŸ³é¢‘
        t = np.linspace(0, 1, 16000)
        audio = np.zeros_like(t)
        
        for h, amp in zip(harmonics, amplitudes):
            freq = fundamental * h
            if freq < 8000:  # é¿å…æ··å 
                audio += amp * np.sin(2 * np.pi * freq * t)
        
        # æ·»åŠ èŠ‚æ‹
        beat = 0.7 + 0.3 * np.sin(2 * np.pi * 2 * t)
        audio *= beat
        
        # è½¬æ¢ä¸ºPCM
        audio = audio / np.max(np.abs(audio)) * 0.3
        pcm = (audio * 32768).astype(np.int16).tobytes()
        
        # æµ‹è¯•è¿‡æ»¤æ•ˆæœ
        result, details = is_speech_like(pcm, 16000)
        
        if not result:
            print(f"   âœ… æˆåŠŸè¿‡æ»¤")
            success_count += 1
        else:
            print(f"   âŒ è¯¯è¯†åˆ«ä¸ºè¯­éŸ³")
        
        print(f"   è°æ³¢å¼ºåº¦: {details.get('harmonic_strength', 0):.3f}")
        print(f"   èŠ‚æ‹è§„å¾‹æ€§: {details.get('beat_regularity', 0):.3f}")
    
    print(f"\næ€»ä½“è¿‡æ»¤æˆåŠŸç‡: {success_count}/{total_count} ({success_count/total_count*100:.1f}%)")
    return success_count / total_count >= 0.8  # 80%ä»¥ä¸ŠæˆåŠŸç‡

def test_edge_cases():
    """æµ‹è¯•è¾¹ç¼˜æƒ…å†µ"""
    print("\n" + "=" * 60)
    print("è¾¹ç¼˜æƒ…å†µæµ‹è¯•")
    print("=" * 60)
    
    edge_cases = []
    
    # æµ‹è¯•1: è½»å£°è¯´è¯
    print("\n1. æµ‹è¯•è½»å£°è¯´è¯:")
    t = np.linspace(0, 1, 16000)
    whisper = 0.05 * np.sin(2 * np.pi * 200 * t) * (1 + 0.3 * np.sin(2 * np.pi * 3 * t))
    whisper_pcm = (whisper * 32768).astype(np.int16).tobytes()
    result, details = is_speech_like(whisper_pcm, 16000)
    print(f"   ç»“æœ: {'[é€šè¿‡]' if result else '[è¢«è¿‡æ»¤]'} - RMS: {details.get('rms', 0):.4f}")
    edge_cases.append(("è½»å£°è¯´è¯", result))
    
    # æµ‹è¯•2: èƒŒæ™¯éŸ³ä¹ + äººå£°
    print("\n2. æµ‹è¯•èƒŒæ™¯éŸ³ä¹ + äººå£°:")
    music = 0.1 * np.sin(2 * np.pi * 440 * t)  # èƒŒæ™¯éŸ³ä¹
    voice = 0.2 * np.sin(2 * np.pi * 150 * t) * (1 + 0.5 * np.sin(2 * np.pi * 4 * t))  # äººå£°
    mixed = music + voice
    mixed_pcm = (mixed * 32768).astype(np.int16).tobytes()
    result, details = is_speech_like(mixed_pcm, 16000)
    print(f"   ç»“æœ: {'[é€šè¿‡]' if result else '[è¢«è¿‡æ»¤]'} - è°æ³¢å¼ºåº¦: {details.get('harmonic_strength', 0):.3f}")
    edge_cases.append(("èƒŒæ™¯éŸ³ä¹+äººå£°", result))
    
    # æµ‹è¯•3: çº¯éŸ³è°ƒï¼ˆå¯èƒ½æ˜¯éŸ³ä¹ä¹Ÿå¯èƒ½æ˜¯è¯­éŸ³ï¼‰
    print("\n3. æµ‹è¯•çº¯éŸ³è°ƒ:")
    pure_tone = 0.2 * np.sin(2 * np.pi * 800 * t)
    pure_pcm = (pure_tone * 32768).astype(np.int16).tobytes()
    result, details = is_speech_like(pure_pcm, 16000)
    print(f"   ç»“æœ: {'[é€šè¿‡]' if result else '[è¢«è¿‡æ»¤]'} - è°ƒåˆ¶èƒ½é‡: {details.get('mod', 0):.3f}")
    edge_cases.append(("çº¯éŸ³è°ƒ", result))
    
    return edge_cases

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("éŸ³ä¹è¿‡æ»¤æ•ˆæœéªŒè¯æµ‹è¯•")
    print("æµ‹è¯•æ—¶é—´:", time.strftime("%Y-%m-%d %H:%M:%S"))
    print("ç›®æ ‡ï¼šè§£å†³è‹±æ–‡æ­Œæ›²è¢«è¯¯è¯†åˆ«ä¸ºä¸­æ–‡è¯­éŸ³çš„é—®é¢˜")
    
    # æ ¸å¿ƒæµ‹è¯•
    music_speech_ok = test_music_vs_speech_detection()
    
    # å„ç§éŸ³ä¹ç±»å‹æµ‹è¯•
    various_music_ok = test_various_music_types()
    
    # è¾¹ç¼˜æƒ…å†µæµ‹è¯•
    edge_cases = test_edge_cases()
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 60)
    
    print(f"âœ… éŸ³ä¹ä¸è¯­éŸ³åŒºåˆ†: {'é€šè¿‡' if music_speech_ok else 'å¤±è´¥'}")
    print(f"âœ… å„ç§éŸ³ä¹ç±»å‹è¿‡æ»¤: {'é€šè¿‡' if various_music_ok else 'å¤±è´¥'}")
    
    print(f"\nè¾¹ç¼˜æƒ…å†µå¤„ç†:")
    for case_name, result in edge_cases:
        print(f"  - {case_name}: {'é€šè¿‡' if result else 'è¢«è¿‡æ»¤'}")
    
    overall_success = music_speech_ok and various_music_ok
    print(f"\nğŸ¯ æ€»ä½“è¯„ä¼°: {'âœ… ä¼˜åŒ–æˆåŠŸ' if overall_success else 'âŒ éœ€è¦è¿›ä¸€æ­¥è°ƒæ•´'}")
    
    if overall_success:
        print("\nğŸ‰ è‹±æ–‡æ­Œæ›²è¿‡æ»¤é—®é¢˜å·²è§£å†³ï¼")
        print("   - ACRCloudéŸ³ä¹è¯†åˆ«é˜ˆå€¼å·²ä¼˜åŒ–")
        print("   - èƒŒæ™¯éŸ³ä¹æ£€æµ‹å‚æ•°å·²è°ƒæ•´")
        print("   - éŸ³é¢‘é—¨æ§ç®—æ³•å·²å¢å¼ºè°æ³¢å’ŒèŠ‚æ‹æ£€æµ‹")
    else:
        print("\nâš ï¸  å»ºè®®è¿›ä¸€æ­¥è°ƒæ•´:")
        print("   - è€ƒè™‘é™ä½è°æ³¢æ£€æµ‹é˜ˆå€¼")
        print("   - è°ƒæ•´èŠ‚æ‹æ£€æµ‹æ•æ„Ÿåº¦")
        print("   - ä¼˜åŒ–äººå£°é¢‘å¸¦åˆ¤æ–­æ¡ä»¶")

if __name__ == "__main__":
    main()