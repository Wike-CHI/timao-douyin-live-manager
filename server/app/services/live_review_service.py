# -*- coding: utf-8 -*-
"""
ç›´æ’­å¤ç›˜æœåŠ¡

è´Ÿè´£åœ¨ç›´æ’­ç»“æŸåç”Ÿæˆå®Œæ•´çš„å¤ç›˜åˆ†ææŠ¥å‘Šï¼ŒåŒ…æ‹¬ï¼š
- æ•°æ®èšåˆï¼ˆå¼¹å¹•ã€è½¬å†™ã€äº‹ä»¶ï¼‰
- è°ƒç”¨ Gemini AI è¿›è¡Œæ·±åº¦åˆ†æ
- ä¿å­˜ç»“æ„åŒ–æŠ¥å‘Šåˆ°æ•°æ®åº“
"""

import json
import logging
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional, List

from sqlalchemy.orm import Session

from ...ai.gemini_adapter import get_gemini_adapter
from ..models.live_review import LiveReviewReport
from ..models.live import LiveSession

logger = logging.getLogger(__name__)


class LiveReviewService:
    """ç›´æ’­å¤ç›˜æœåŠ¡"""
    
    def __init__(self):
        self.gemini = get_gemini_adapter()
        self.persist_root = os.getenv("PERSIST_ROOT", "records/live_logs")
    
    def generate_review(self, session_id: int, db: Session) -> Optional[LiveReviewReport]:
        """ç”Ÿæˆç›´æ’­å¤ç›˜æŠ¥å‘Š
        
        Args:
            session_id: ç›´æ’­ä¼šè¯ ID
            db: æ•°æ®åº“ä¼šè¯
        
        Returns:
            LiveReviewReport å¯¹è±¡æˆ– None
        """
        if not self.gemini.is_available():
            logger.error("âŒ Gemini æœåŠ¡ä¸å¯ç”¨ï¼Œæ— æ³•ç”Ÿæˆå¤ç›˜æŠ¥å‘Š")
            logger.info("è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½® AIHUBMIX_API_KEY")
            return None
        
        # æŸ¥è¯¢ç›´æ’­ä¼šè¯
        session = db.query(LiveSession).filter(LiveSession.id == session_id).first()
        if not session:
            logger.error(f"âŒ ç›´æ’­ä¼šè¯ä¸å­˜åœ¨: session_id={session_id}")
            return None
        
        if session.status != "ended":
            logger.warning(f"âš ï¸ ç›´æ’­å°šæœªç»“æŸï¼Œæ— æ³•ç”Ÿæˆå¤ç›˜: session_id={session_id}, status={session.status}")
            return None
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨æŠ¥å‘Š
        existing_report = db.query(LiveReviewReport).filter(
            LiveReviewReport.session_id == session_id
        ).first()
        if existing_report:
            logger.info(f"â„¹ï¸ å¤ç›˜æŠ¥å‘Šå·²å­˜åœ¨ï¼Œå°†é‡æ–°ç”Ÿæˆ: session_id={session_id}")
            db.delete(existing_report)
            db.flush()
        
        logger.info(f"ğŸš€ å¼€å§‹ç”Ÿæˆå¤ç›˜æŠ¥å‘Š: session_id={session_id}, room_id={session.room_id}")
        
        # 1. åŠ è½½ç›´æ’­æ•°æ®
        context_data = self._load_session_data(session)
        
        # 2. æ„å»º Prompt
        prompt = self._build_review_prompt(session, context_data)
        
        # 3. è°ƒç”¨ Gemini
        response = self.gemini.generate_review(
            prompt=prompt, 
            temperature=0.3, 
            max_tokens=4096,
            response_format="json"
        )
        
        if not response:
            logger.error("âŒ Gemini è°ƒç”¨å¤±è´¥")
            # åˆ›å»ºå¤±è´¥è®°å½•
            report = LiveReviewReport(
                session_id=session_id,
                status="failed",
                error_message="Gemini API è°ƒç”¨å¤±è´¥",
                ai_model=self.gemini.model
            )
            db.add(report)
            db.commit()
            return None
        
        # 4. è§£æå“åº”
        result = self.gemini.parse_json_response(response["text"])
        if not result:
            logger.error("âŒ æ— æ³•è§£æ Gemini å“åº”ä¸º JSON")
            # ä¿å­˜åŸå§‹æ–‡æœ¬ä½œä¸ºé™çº§æ–¹æ¡ˆ
            report = LiveReviewReport(
                session_id=session_id,
                full_report_text=response["text"],
                status="completed",
                ai_model=self.gemini.model,
                generation_cost=response["cost"],
                generation_tokens=response["usage"]["total_tokens"],
                generation_duration=response["duration"]
            )
            db.add(report)
            db.commit()
            logger.warning("âš ï¸ å·²ä¿å­˜åŸå§‹æ–‡æœ¬æŠ¥å‘Šï¼ˆæœªç»“æ„åŒ–ï¼‰")
            return report
        
        # 5. ä¿å­˜æŠ¥å‘Šåˆ°æ•°æ®åº“
        report = LiveReviewReport(
            session_id=session_id,
            overall_score=result.get("overall_score", 0),
            performance_analysis=result.get("performance_analysis", {}),
            key_highlights=result.get("key_highlights", []),
            key_issues=result.get("key_issues", []),
            improvement_suggestions=result.get("improvement_suggestions", []),
            full_report_text=self._format_markdown_report(result),
            status="completed",
            ai_model=self.gemini.model,
            generation_cost=response["cost"],
            generation_tokens=response["usage"]["total_tokens"],
            generation_duration=response["duration"]
        )
        
        db.add(report)
        db.flush()
        
        # 6. æ›´æ–° session çš„ AI ä½¿ç”¨è®°å½•
        session.ai_usage_count += 1
        session.ai_usage_tokens += response["usage"]["total_tokens"]
        session.ai_usage_cost += float(response["cost"])
        
        db.commit()
        
        logger.info(
            f"âœ… å¤ç›˜æŠ¥å‘Šç”ŸæˆæˆåŠŸ: report_id={report.id}, "
            f"score={report.overall_score}, "
            f"cost=${report.generation_cost:.6f}, "
            f"duration={report.generation_duration:.2f}s"
        )
        
        return report
    
    def _load_session_data(self, session: LiveSession) -> Dict[str, Any]:
        """åŠ è½½ç›´æ’­æ•°æ®æ–‡ä»¶
        
        ä» records/live_logs/ ç›®å½•åŠ è½½å¼¹å¹•ã€è½¬å†™ã€äº‹ä»¶æ•°æ®
        
        Args:
            session: LiveSession å¯¹è±¡
        
        Returns:
            {
                "comments": List[Dict],  # å¼¹å¹•åˆ—è¡¨
                "transcript": str,       # è½¬å†™æ–‡æœ¬
                "events": List[Dict]     # äº‹ä»¶åˆ—è¡¨
            }
        """
        data = {
            "comments": [],
            "transcript": "",
            "events": [],
            "comments_summary": {},
            "transcript_summary": {}
        }
        
        # è¯»å–å¼¹å¹•æ–‡ä»¶
        if session.comment_file and Path(session.comment_file).exists():
            try:
                with open(session.comment_file, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                    data["comments"] = [json.loads(line) for line in lines if line.strip()]
                    logger.info(f"âœ… åŠ è½½å¼¹å¹•æ•°æ®: {len(data['comments'])} æ¡")
            except Exception as e:
                logger.warning(f"âš ï¸ è¯»å–å¼¹å¹•æ–‡ä»¶å¤±è´¥: {e}")
        else:
            logger.warning(f"âš ï¸ å¼¹å¹•æ–‡ä»¶ä¸å­˜åœ¨: {session.comment_file}")
        
        # è¯»å–è½¬å†™æ–‡ä»¶
        if session.transcript_file and Path(session.transcript_file).exists():
            try:
                with open(session.transcript_file, 'r', encoding='utf-8') as f:
                    data["transcript"] = f.read()
                    logger.info(f"âœ… åŠ è½½è½¬å†™æ•°æ®: {len(data['transcript'])} å­—ç¬¦")
            except Exception as e:
                logger.warning(f"âš ï¸ è¯»å–è½¬å†™æ–‡ä»¶å¤±è´¥: {e}")
        else:
            logger.warning(f"âš ï¸ è½¬å†™æ–‡ä»¶ä¸å­˜åœ¨: {session.transcript_file}")
        
        # å¦‚æœæ²¡æœ‰å…·ä½“æ–‡ä»¶è·¯å¾„ï¼Œå°è¯•ä»é»˜è®¤è·¯å¾„åŠ è½½
        if not data["comments"] and not data["transcript"]:
            data = self._load_from_default_path(session)
        
        # ç”Ÿæˆæ‘˜è¦ï¼ˆé¿å… Prompt è¿‡é•¿ï¼‰
        data["comments_summary"] = self._summarize_comments(data["comments"])
        data["transcript_summary"] = self._summarize_transcript(data["transcript"])
        
        return data
    
    def _load_from_default_path(self, session: LiveSession) -> Dict[str, Any]:
        """ä»é»˜è®¤è·¯å¾„åŠ è½½æ•°æ®"""
        data = {"comments": [], "transcript": "", "events": []}
        
        # records/live_logs/<room_id>/<date>/
        if session.start_time:
            date_str = session.start_time.strftime("%Y-%m-%d")
            base_path = Path(self.persist_root) / session.room_id / date_str
            
            if base_path.exists():
                # æŸ¥æ‰¾å¼¹å¹•æ–‡ä»¶
                comment_files = list(base_path.glob("comments_*.jsonl"))
                if comment_files:
                    try:
                        with open(comment_files[0], 'r', encoding='utf-8') as f:
                            data["comments"] = [json.loads(line) for line in f if line.strip()]
                            logger.info(f"âœ… ä»é»˜è®¤è·¯å¾„åŠ è½½å¼¹å¹•: {len(data['comments'])} æ¡")
                    except Exception as e:
                        logger.warning(f"âš ï¸ ä»é»˜è®¤è·¯å¾„è¯»å–å¼¹å¹•å¤±è´¥: {e}")
                
                # æŸ¥æ‰¾è½¬å†™æ–‡ä»¶
                transcript_files = list(base_path.glob("transcript_*.txt"))
                if transcript_files:
                    try:
                        with open(transcript_files[0], 'r', encoding='utf-8') as f:
                            data["transcript"] = f.read()
                            logger.info(f"âœ… ä»é»˜è®¤è·¯å¾„åŠ è½½è½¬å†™: {len(data['transcript'])} å­—ç¬¦")
                    except Exception as e:
                        logger.warning(f"âš ï¸ ä»é»˜è®¤è·¯å¾„è¯»å–è½¬å†™å¤±è´¥: {e}")
        
        return data
    
    def _summarize_comments(self, comments: List[Dict]) -> Dict[str, Any]:
        """å¼¹å¹•æ‘˜è¦
        
        æå–å‰100æ¡ã€çƒ­é—¨è¯„è®ºã€é«˜ä»·å€¼ç”¨æˆ·ç­‰
        """
        if not comments:
            return {
                "total": 0,
                "sample": [],
                "hot_users": []
            }
        
        # å–å‰100æ¡ä½œä¸ºæ ·æœ¬
        sample = comments[:100]
        
        # ç»Ÿè®¡æ´»è·ƒç”¨æˆ·
        user_counts = {}
        for comment in comments:
            user = comment.get("user") or comment.get("nickname") or "åŒ¿å"
            user_counts[user] = user_counts.get(user, 0) + 1
        
        # å–å‰10åæ´»è·ƒç”¨æˆ·
        hot_users = sorted(user_counts.items(), key=lambda x: x[1], reverse=True)[:10]
        
        return {
            "total": len(comments),
            "sample": sample,
            "hot_users": [{"user": u, "count": c} for u, c in hot_users]
        }
    
    def _summarize_transcript(self, transcript: str) -> Dict[str, Any]:
        """è½¬å†™æ‘˜è¦
        
        æå–å…³é”®ç‰‡æ®µï¼ˆé¦–å°¾å„500å­—ï¼‰
        """
        if not transcript:
            return {
                "total_chars": 0,
                "opening": "",
                "closing": ""
            }
        
        return {
            "total_chars": len(transcript),
            "opening": transcript[:500] if len(transcript) > 500 else transcript,
            "closing": transcript[-500:] if len(transcript) > 500 else ""
        }
    
    def _build_review_prompt(self, session: LiveSession, data: Dict[str, Any]) -> str:
        """æ„å»º Gemini åˆ†æ Prompt
        
        åŒ…å«ç›´æ’­åŸºæœ¬æ•°æ®ã€å¼¹å¹•æ ·æœ¬ã€è½¬å†™ç‰‡æ®µç­‰
        """
        # æ ¼å¼åŒ–å¼¹å¹•æ ·æœ¬
        comments_text = "\n".join([
            f"{i+1}. {c.get('user', 'åŒ¿å')}: {c.get('text', c.get('content', ''))}"
            for i, c in enumerate(data["comments_summary"].get("sample", [])[:50])
        ])
        
        # æ ¼å¼åŒ–æ´»è·ƒç”¨æˆ·
        hot_users_text = "\n".join([
            f"- {u['user']}: {u['count']} æ¡è¯„è®º"
            for u in data["comments_summary"].get("hot_users", [])[:10]
        ])
        
        # æ„å»º Prompt
        prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ç›´æ’­è¿è¥åˆ†æå¸ˆï¼Œè¯·å¯¹ä»¥ä¸‹ç›´æ’­æ•°æ®è¿›è¡Œ**å…¨é¢å¤ç›˜åˆ†æ**ï¼Œå¹¶ç»™å‡ºæœªæ¥æ”¹è¿›å»ºè®®ã€‚

# ç›´æ’­åŸºæœ¬ä¿¡æ¯
- **ç›´æ’­å¹³å°**: {session.platform}
- **ç›´æ’­é—´ID**: {session.room_id}
- **ç›´æ’­æ ‡é¢˜**: {session.title or "ï¼ˆæ— æ ‡é¢˜ï¼‰"}
- **å¼€å§‹æ—¶é—´**: {session.start_time.strftime("%Y-%m-%d %H:%M:%S") if session.start_time else "æœªçŸ¥"}
- **ç»“æŸæ—¶é—´**: {session.end_time.strftime("%Y-%m-%d %H:%M:%S") if session.end_time else "æœªçŸ¥"}
- **ç›´æ’­æ—¶é•¿**: {session.duration // 60} åˆ†é’Ÿ {session.duration % 60} ç§’
- **æ€»è§‚çœ‹äººæ•°**: {session.total_viewers}
- **å³°å€¼åœ¨çº¿**: {session.peak_viewers}
- **å¹³å‡åœ¨çº¿**: {session.avg_viewers}
- **è¯„è®ºæ•°**: {session.comment_count}
- **ç‚¹èµæ•°**: {session.like_count}
- **ç¤¼ç‰©æ•°**: {session.gift_count}ï¼ˆä»·å€¼ Â¥{session.gift_value}ï¼‰

# ä¸»æ’­å£æ’­å†…å®¹ï¼ˆè¯­éŸ³è½¬å†™ç‰‡æ®µï¼‰
## å¼€åœºç‰‡æ®µï¼š
```
{data["transcript_summary"].get("opening", "ï¼ˆæ— è½¬å†™æ•°æ®ï¼‰")}
```

## ç»“å°¾ç‰‡æ®µï¼š
```
{data["transcript_summary"].get("closing", "")}
```

**è½¬å†™æ€»å­—æ•°**: {data["transcript_summary"].get("total_chars", 0)}

# è§‚ä¼—å¼¹å¹•æ ·æœ¬ï¼ˆå‰ 50 æ¡ï¼‰
{comments_text or "ï¼ˆæ— å¼¹å¹•æ•°æ®ï¼‰"}

**å¼¹å¹•æ€»æ•°**: {data["comments_summary"].get("total", 0)}

# æ´»è·ƒè§‚ä¼— TOP 10
{hot_users_text or "ï¼ˆæ— æ•°æ®ï¼‰"}

---

# åˆ†æè¦æ±‚

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON ç»“æ„è¾“å‡ºåˆ†æç»“æœï¼ˆ**åªè¿”å›JSONï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—è¯´æ˜**ï¼‰ï¼š

{{
  "overall_score": 75,  // ç»¼åˆè¯„åˆ† 0-100ï¼ŒåŸºäºæ•°æ®å®¢è§‚è¯„ä¼°
  "performance_analysis": {{
    "engagement": {{
      "score": 80,  // äº’åŠ¨è¡¨ç°è¯„åˆ† 0-100
      "highlights": ["äº’åŠ¨é¢‘ç¹", "å›å¤åŠæ—¶"],  // äº®ç‚¹ï¼ˆ2-5ä¸ªï¼‰
      "issues": ["ä¸­é€”å†·åœº10åˆ†é’Ÿ"]  // é—®é¢˜ï¼ˆ0-3ä¸ªï¼‰
    }},
    "content_quality": {{
      "score": 70,  // å†…å®¹è´¨é‡è¯„åˆ† 0-100
      "highlights": ["äº§å“è®²è§£æ¸…æ™°"],
      "issues": ["è¯é¢˜é‡å¤", "ç¼ºå°‘æ–°é²œæ„Ÿ"]
    }},
    "conversion": {{
      "score": 65,  // è½¬åŒ–æ½œåŠ›è¯„åˆ† 0-100
      "signals": ["è¯¢ä»·å¤šä½†æˆäº¤å°‘", "ç¼ºå°‘é™æ—¶ä¼˜æƒ "]  // è½¬åŒ–ä¿¡å·ï¼ˆ2-5ä¸ªï¼‰
    }}
  }},
  "key_highlights": [
    "å¼€åœº3åˆ†é’Ÿå¸å¼•è§‚ä¼—ï¼Œåœ¨çº¿äººæ•°å¿«é€Ÿå¢é•¿",
    "20:15 åœ¨çº¿äººæ•°è¾¾åˆ°å³°å€¼ {session.peak_viewers} äºº",
    "20:32 æ”¶åˆ°å•ç¬”æœ€å¤§ç¤¼ç‰© Â¥{session.gift_value / session.gift_count if session.gift_count > 0 else 0:.2f}"
  ],  // 3-5ä¸ªäº®ç‚¹æ—¶åˆ»
  "key_issues": [
    "ä¸­é€”ç½‘ç»œæ³¢åŠ¨å¯¼è‡´å¡é¡¿",
    "è¯é¢˜åˆ‡æ¢è¿‡äºçªç„¶ï¼Œè§‚ä¼—è·Ÿä¸ä¸ŠèŠ‚å¥",
    "ç»“å°¾è‰ç‡ï¼Œæœªåšå¥½å‘Šåˆ«å’Œé¢„å‘Š"
  ],  // 2-5ä¸ªä¸»è¦é—®é¢˜
  "improvement_suggestions": [
    {{
      "priority": "high",  // high/medium/low
      "category": "äº’åŠ¨æŠ€å·§",
      "action": "å¢åŠ è§‚ä¼—æé—®ç¯èŠ‚ï¼Œæ¯15åˆ†é’Ÿä¸»åŠ¨é‚€è¯·è§‚ä¼—ç•™è¨€",
      "expected_impact": "æå‡ç•™å­˜ç‡å’Œå‚ä¸åº¦"
    }},
    {{
      "priority": "medium",
      "category": "å†…å®¹è§„åˆ’",
      "action": "æå‰å‡†å¤‡3-5ä¸ªå¤‡ç”¨è¯é¢˜å’Œäº§å“å–ç‚¹",
      "expected_impact": "é¿å…å†·åœºï¼Œä¿æŒèŠ‚å¥"
    }},
    {{
      "priority": "medium",
      "category": "æŠ€æœ¯å‡†å¤‡",
      "action": "ç›´æ’­å‰æµ‹è¯•ç½‘ç»œï¼Œå‡†å¤‡ 4G çƒ­ç‚¹å¤‡ç”¨",
      "expected_impact": "å‡å°‘æŠ€æœ¯æ•…éšœ"
    }},
    {{
      "priority": "low",
      "category": "è¥é”€ç­–ç•¥",
      "action": "è®¾ç½®é™æ—¶ä¼˜æƒ å’Œäº’åŠ¨æ¸¸æˆï¼Œæå‡è½¬åŒ–",
      "expected_impact": "å¢åŠ æˆäº¤æœºä¼š"
    }}
  ]  // 4-6æ¡å»ºè®®ï¼ŒæŒ‰ä¼˜å…ˆçº§æ’åº
}}

**è¯„åˆ†è¯´æ˜**ï¼š
- 90-100åˆ†ï¼šä¼˜ç§€ï¼Œè¶…å‡ºé¢„æœŸ
- 80-89åˆ†ï¼šè‰¯å¥½ï¼Œç¬¦åˆé¢„æœŸ
- 70-79åˆ†ï¼šåˆæ ¼ï¼Œæœ‰æå‡ç©ºé—´
- 60-69åˆ†ï¼šå¾…æ”¹è¿›ï¼Œå­˜åœ¨æ˜æ˜¾é—®é¢˜
- <60åˆ†ï¼šè¾ƒå·®ï¼Œéœ€è¦é‡ç‚¹æ”¹è¿›

**æ³¨æ„äº‹é¡¹**ï¼š
1. è¯„åˆ†è¦å®¢è§‚ï¼ŒåŸºäºå®é™…æ•°æ®ï¼ˆè§‚çœ‹äººæ•°ã€äº’åŠ¨é‡ã€æ—¶é•¿ç­‰ï¼‰
2. äº®ç‚¹å’Œé—®é¢˜è¦å…·ä½“ï¼Œå°½é‡å…³è”æ—¶é—´ç‚¹æˆ–æ•°æ®
3. å»ºè®®è¦å¯æ‰§è¡Œï¼Œé¿å…ç©ºè¯å¥—è¯
4. ä¼˜å…ˆçº§ highï¼ˆç«‹å³æ”¹è¿›ï¼‰ã€mediumï¼ˆçŸ­æœŸä¼˜åŒ–ï¼‰ã€lowï¼ˆé•¿æœŸæå‡ï¼‰
5. **åªè¿”å› JSONï¼Œä¸è¦æœ‰å…¶ä»–è§£é‡Šæ€§æ–‡å­—**
"""
        
        return prompt
    
    def _format_markdown_report(self, result: Dict[str, Any]) -> str:
        """å°† JSON ç»“æœæ ¼å¼åŒ–ä¸º Markdown æŠ¥å‘Š
        
        Args:
            result: Gemini è¿”å›çš„ç»“æ„åŒ–æ•°æ®
        
        Returns:
            Markdown æ ¼å¼çš„æŠ¥å‘Šæ–‡æœ¬
        """
        md = f"""# ğŸ“Š ç›´æ’­å¤ç›˜æŠ¥å‘Š

## ç»¼åˆè¯„åˆ†ï¼š{result.get('overall_score', 0)} / 100

"""
        
        # è¯„åˆ†ç­‰çº§
        score = result.get('overall_score', 0)
        if score >= 90:
            md += "**ç­‰çº§**ï¼šâ­â­â­â­â­ ä¼˜ç§€\n\n"
        elif score >= 80:
            md += "**ç­‰çº§**ï¼šâ­â­â­â­ è‰¯å¥½\n\n"
        elif score >= 70:
            md += "**ç­‰çº§**ï¼šâ­â­â­ åˆæ ¼\n\n"
        elif score >= 60:
            md += "**ç­‰çº§**ï¼šâ­â­ å¾…æ”¹è¿›\n\n"
        else:
            md += "**ç­‰çº§**ï¼šâ­ éœ€é‡ç‚¹æ”¹è¿›\n\n"
        
        md += "---\n\n"
        
        # äº®ç‚¹æ—¶åˆ»
        md += "## âœ¨ äº®ç‚¹æ—¶åˆ»\n\n"
        for highlight in result.get("key_highlights", []):
            md += f"- {highlight}\n"
        md += "\n"
        
        # ä¸»è¦é—®é¢˜
        md += "## âš ï¸ ä¸»è¦é—®é¢˜\n\n"
        issues = result.get("key_issues", [])
        if issues:
            for issue in issues:
                md += f"- {issue}\n"
        else:
            md += "- æš‚æ— æ˜æ˜¾é—®é¢˜\n"
        md += "\n"
        
        # è¡¨ç°åˆ†æ
        md += "## ğŸ“ˆ è¡¨ç°åˆ†æ\n\n"
        perf = result.get("performance_analysis", {})
        
        for category, data in perf.items():
            category_name = {
                "engagement": "äº’åŠ¨è¡¨ç°",
                "content_quality": "å†…å®¹è´¨é‡",
                "conversion": "è½¬åŒ–æ½œåŠ›"
            }.get(category, category)
            
            score = data.get('score', 0)
            md += f"### {category_name} ({score}/100)\n\n"
            
            if data.get("highlights"):
                md += "**äº®ç‚¹**ï¼š\n"
                for h in data["highlights"]:
                    md += f"- âœ… {h}\n"
            
            if data.get("issues"):
                md += "\n**é—®é¢˜**ï¼š\n"
                for i in data["issues"]:
                    md += f"- âŒ {i}\n"
            
            if data.get("signals"):
                md += "\n**ä¿¡å·**ï¼š\n"
                for s in data["signals"]:
                    md += f"- ğŸ“Š {s}\n"
            
            md += "\n"
        
        # æ”¹è¿›å»ºè®®
        md += "## ğŸ’¡ æ”¹è¿›å»ºè®®\n\n"
        suggestions = result.get("improvement_suggestions", [])
        
        # æŒ‰ä¼˜å…ˆçº§åˆ†ç»„
        high_priority = [s for s in suggestions if s.get("priority") == "high"]
        medium_priority = [s for s in suggestions if s.get("priority") == "medium"]
        low_priority = [s for s in suggestions if s.get("priority") == "low"]
        
        if high_priority:
            md += "### ğŸ”´ é«˜ä¼˜å…ˆçº§ï¼ˆç«‹å³æ”¹è¿›ï¼‰\n\n"
            for sug in high_priority:
                md += f"**{sug.get('category', 'å…¶ä»–')}**\n"
                md += f"- **è¡ŒåŠ¨**ï¼š{sug.get('action', '')}\n"
                md += f"- **é¢„æœŸæ•ˆæœ**ï¼š{sug.get('expected_impact', '')}\n\n"
        
        if medium_priority:
            md += "### ğŸŸ¡ ä¸­ä¼˜å…ˆçº§ï¼ˆçŸ­æœŸä¼˜åŒ–ï¼‰\n\n"
            for sug in medium_priority:
                md += f"**{sug.get('category', 'å…¶ä»–')}**\n"
                md += f"- **è¡ŒåŠ¨**ï¼š{sug.get('action', '')}\n"
                md += f"- **é¢„æœŸæ•ˆæœ**ï¼š{sug.get('expected_impact', '')}\n\n"
        
        if low_priority:
            md += "### ğŸŸ¢ ä½ä¼˜å…ˆçº§ï¼ˆé•¿æœŸæå‡ï¼‰\n\n"
            for sug in low_priority:
                md += f"**{sug.get('category', 'å…¶ä»–')}**\n"
                md += f"- **è¡ŒåŠ¨**ï¼š{sug.get('action', '')}\n"
                md += f"- **é¢„æœŸæ•ˆæœ**ï¼š{sug.get('expected_impact', '')}\n\n"
        
        # ç»“å°¾
        md += "---\n\n"
        md += f"*æŠ¥å‘Šç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\n"
        md += f"*ç”± Gemini 2.5 Flash æä¾›æŠ€æœ¯æ”¯æŒ*\n"
        
        return md


# å…¨å±€å•ä¾‹
_live_review_service: Optional[LiveReviewService] = None


def get_live_review_service() -> LiveReviewService:
    """è·å–ç›´æ’­å¤ç›˜æœåŠ¡å•ä¾‹"""
    global _live_review_service
    if _live_review_service is None:
        _live_review_service = LiveReviewService()
    return _live_review_service
