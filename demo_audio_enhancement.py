#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
éŸ³é¢‘å¢å¼ºåŠŸèƒ½æ¼”ç¤ºè„šæœ¬
å±•ç¤ºå¦‚ä½•ä½¿ç”¨éŸ³é¢‘å¢å¼ºæ¨¡å—æå‡è¯­éŸ³è¯†åˆ«æ•ˆæœ
"""

import sys
import os
import time
import json
import logging
import numpy as np
from pathlib import Path
from pydub import AudioSegment

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_path = Path(__file__).parent
sys.path.insert(0, str(project_path))

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

try:
    import vosk
    from audio_enhancer import AudioEnhancer, EnhancedKaldiRecognizer
    logger.info("âœ… æˆåŠŸå¯¼å…¥æ‰€éœ€æ¨¡å—")
except ImportError as e:
    logger.error(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    sys.exit(1)

def load_test_audio(audio_path: str) -> tuple:
    """åŠ è½½å¹¶è½¬æ¢æµ‹è¯•éŸ³é¢‘"""
    logger.info("ğŸ”„ åŠ è½½æµ‹è¯•éŸ³é¢‘...")
    
    try:
        # åŠ è½½éŸ³é¢‘
        audio = AudioSegment.from_file(audio_path)
        logger.info(f"   åŸå§‹éŸ³é¢‘: {audio.frame_rate}Hz, {audio.channels}å£°é“, {len(audio)/1000:.2f}ç§’")
        
        # è½¬æ¢ä¸ºå•å£°é“16kHz
        if audio.channels > 1:
            audio = audio.set_channels(1)
        if audio.frame_rate != 16000:
            audio = audio.set_frame_rate(16000)
        audio = audio.set_sample_width(2)  # 16-bit
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        samples = np.array(audio.get_array_of_samples())
        logger.info(f"   è½¬æ¢åéŸ³é¢‘: {len(samples)} é‡‡æ ·ç‚¹")
        
        return samples, audio.frame_rate
    except Exception as e:
        logger.error(f"âŒ éŸ³é¢‘åŠ è½½å¤±è´¥: {e}")
        return None, None

def compare_recognizers(audio_data: np.ndarray, sample_rate: int):
    """æ¯”è¾ƒæ ‡å‡†è¯†åˆ«å™¨å’Œå¢å¼ºç‰ˆè¯†åˆ«å™¨"""
    logger.info("ğŸ” å¼€å§‹æ¯”è¾ƒæµ‹è¯•...")
    
    # åˆå§‹åŒ–æ¨¡å‹
    logger.info("   åŠ è½½VOSKæ¨¡å‹...")
    model = vosk.Model(model_name="vosk-model-small-cn-0.22")
    
    # æµ‹è¯•1: æ ‡å‡†è¯†åˆ«å™¨
    logger.info("   æµ‹è¯•æ ‡å‡†è¯†åˆ«å™¨...")
    standard_recognizer = vosk.KaldiRecognizer(model, sample_rate)
    standard_recognizer.SetWords(True)
    
    start_time = time.time()
    results = []
    
    # åˆ†å—å¤„ç†éŸ³é¢‘
    chunk_size = 4000  # 4000 bytes â‰ˆ 0.25ç§’ (16kHz, 16-bit)
    chunk_samples = chunk_size // 2
    
    total_samples = len(audio_data)
    processed_samples = 0
    
    while processed_samples < total_samples:
        chunk_end = min(processed_samples + chunk_samples, total_samples)
        chunk = audio_data[processed_samples:chunk_end]
        chunk_bytes = chunk.tobytes()
        
        if standard_recognizer.AcceptWaveform(chunk_bytes):
            result = json.loads(standard_recognizer.Result())
            if result.get('text', '').strip():
                results.append(result)
        
        processed_samples = chunk_end
    
    # è·å–æœ€ç»ˆç»“æœ
    final_result = json.loads(standard_recognizer.FinalResult())
    if final_result.get('text', '').strip():
        results.append(final_result)
    
    standard_time = time.time() - start_time
    
    # åˆå¹¶ç»“æœ
    standard_text = ' '.join([r.get('text', '') for r in results if r.get('text', '').strip()])
    standard_words = sum([len(r.get('result', [])) for r in results])
    
    logger.info(f"   æ ‡å‡†è¯†åˆ«å™¨ç»“æœ: {standard_text[:100]}{'...' if len(standard_text) > 100 else ''}")
    logger.info(f"   è¯†åˆ«è¯æ•°: {standard_words}")
    logger.info(f"   å¤„ç†æ—¶é—´: {standard_time:.2f}ç§’")
    
    # æµ‹è¯•2: å¢å¼ºç‰ˆè¯†åˆ«å™¨
    logger.info("   æµ‹è¯•å¢å¼ºç‰ˆè¯†åˆ«å™¨...")
    base_recognizer = vosk.KaldiRecognizer(model, sample_rate)
    base_recognizer.SetWords(True)
    
    enhanced_recognizer = EnhancedKaldiRecognizer(
        base_recognizer,
        enable_audio_enhancement=True,
        noise_reduction_strength=0.5,
        gain_target=0.7
    )
    enhanced_recognizer.EnableAudioEnhancement(True)
    
    start_time = time.time()
    results = []
    
    processed_samples = 0
    while processed_samples < total_samples:
        chunk_end = min(processed_samples + chunk_samples, total_samples)
        chunk = audio_data[processed_samples:chunk_end]
        chunk_bytes = chunk.tobytes()
        
        if enhanced_recognizer.AcceptWaveform(chunk_bytes):
            result = json.loads(enhanced_recognizer.Result())
            if result.get('text', '').strip():
                results.append(result)
        
        processed_samples = chunk_end
    
    # è·å–æœ€ç»ˆç»“æœ
    final_result = json.loads(enhanced_recognizer.FinalResult())
    if final_result.get('text', '').strip():
        results.append(final_result)
    
    enhanced_time = time.time() - start_time
    
    # åˆå¹¶ç»“æœ
    enhanced_text = ' '.join([r.get('text', '') for r in results if r.get('text', '').strip()])
    enhanced_words = sum([len(r.get('result', [])) for r in results])
    
    logger.info(f"   å¢å¼ºç‰ˆè¯†åˆ«å™¨ç»“æœ: {enhanced_text[:100]}{'...' if len(enhanced_text) > 100 else ''}")
    logger.info(f"   è¯†åˆ«è¯æ•°: {enhanced_words}")
    logger.info(f"   å¤„ç†æ—¶é—´: {enhanced_time:.2f}ç§’")
    
    # è·å–å¢å¼ºç»Ÿè®¡ä¿¡æ¯
    enhancement_stats = enhanced_recognizer.GetEnhancementStats()
    logger.info(f"   å¢å¼ºå¤„ç†å—æ•°: {enhancement_stats.get('processed_chunks', 0)}")
    logger.info(f"   å¹³å‡å¢å¼ºæ—¶é—´: {enhancement_stats.get('average_enhancement_time', 0)*1000:.2f}æ¯«ç§’")
    
    # è¾“å‡ºæ¯”è¾ƒç»“æœ
    logger.info("ğŸ“Š æµ‹è¯•ç»“æœæ¯”è¾ƒ:")
    logger.info(f"   æ–‡æœ¬ç›¸ä¼¼åº¦: {calculate_similarity(standard_text, enhanced_text):.1f}%")
    logger.info(f"   è¯æ•°å·®å¼‚: {enhanced_words - standard_words}")
    logger.info(f"   æ—¶é—´å·®å¼‚: {enhanced_time - standard_time:+.2f}ç§’")

def calculate_similarity(text1: str, text2: str) -> float:
    """è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦"""
    if not text1 and not text2:
        return 100.0
    if not text1 or not text2:
        return 0.0
        
    words1 = set(text1.split())
    words2 = set(text2.split())
    
    if not words1 and not words2:
        return 100.0
        
    intersection = len(words1.intersection(words2))
    union = len(words1.union(words2))
    
    return (intersection / union * 100) if union > 0 else 0.0

def demo_audio_enhancer():
    """æ¼”ç¤ºéŸ³é¢‘å¢å¼ºå™¨çš„ç‹¬ç«‹ä½¿ç”¨"""
    logger.info("ğŸ”Š æ¼”ç¤ºéŸ³é¢‘å¢å¼ºå™¨ç‹¬ç«‹ä½¿ç”¨...")
    
    # åˆ›å»ºå¢å¼ºå™¨
    enhancer = AudioEnhancer(sample_rate=16000)
    
    # è®¾ç½®å‚æ•°
    enhancer.set_noise_reduction(0.6)
    enhancer.set_gain_target(0.8)
    
    logger.info("   éŸ³é¢‘å¢å¼ºå™¨å·²é…ç½®:")
    logger.info("   - é™å™ªå¼ºåº¦: 0.6")
    logger.info("   - å¢ç›Šç›®æ ‡: 0.8")
    logger.info("   - é‡‡æ ·ç‡: 16000Hz")
    
    # ç”Ÿæˆæµ‹è¯•éŸ³é¢‘æ•°æ®(æ¨¡æ‹Ÿ)
    test_duration = 1.0  # 1ç§’
    sample_rate = 16000
    samples = int(test_duration * sample_rate)
    
    # ç”Ÿæˆå¸¦å™ªå£°çš„æ­£å¼¦æ³¢ä¿¡å·
    t = np.linspace(0, test_duration, samples, False)
    signal = np.sin(2 * np.pi * 440 * t)  # 440Hzæ­£å¼¦æ³¢
    
    # æ·»åŠ å™ªå£°
    noise = np.random.normal(0, 0.1, samples)
    noisy_signal = signal + noise
    
    # å½’ä¸€åŒ–å¹¶è½¬æ¢ä¸ºint16
    noisy_signal = np.clip(noisy_signal * 32767, -32768, 32767).astype(np.int16)
    audio_bytes = noisy_signal.tobytes()
    
    logger.info(f"   ç”Ÿæˆæµ‹è¯•éŸ³é¢‘: {len(audio_bytes)} å­—èŠ‚")
    
    # åº”ç”¨å¢å¼º
    start_time = time.time()
    enhanced_bytes = enhancer.enhance_audio(audio_bytes)
    enhance_time = time.time() - start_time
    
    logger.info(f"   å¢å¼ºåéŸ³é¢‘: {len(enhanced_bytes)} å­—èŠ‚")
    logger.info(f"   å¤„ç†æ—¶é—´: {enhance_time*1000:.2f}æ¯«ç§’")
    logger.info("âœ… éŸ³é¢‘å¢å¼ºæ¼”ç¤ºå®Œæˆ")

def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸ™ï¸ éŸ³é¢‘å¢å¼ºåŠŸèƒ½æ¼”ç¤ºå¼€å§‹")
    logger.info("=" * 50)
    
    # æ¼”ç¤ºéŸ³é¢‘å¢å¼ºå™¨ç‹¬ç«‹ä½¿ç”¨
    demo_audio_enhancer()
    
    # æŸ¥æ‰¾æµ‹è¯•éŸ³é¢‘æ–‡ä»¶
    test_audio_path = project_path / "tests" / "å½•éŸ³ (12).m4a"
    
    if not test_audio_path.exists():
        logger.warning(f"âš ï¸  æ‰¾ä¸åˆ°æµ‹è¯•éŸ³é¢‘æ–‡ä»¶: {test_audio_path}")
        logger.info("è¯·ç¡®ä¿testsç›®å½•ä¸­æœ‰å½•éŸ³æ–‡ä»¶")
        return
    
    logger.info(f"ğŸ“ ä½¿ç”¨æµ‹è¯•éŸ³é¢‘: {test_audio_path}")
    
    # åŠ è½½éŸ³é¢‘
    audio_data, sample_rate = load_test_audio(str(test_audio_path))
    if audio_data is None:
        return
    
    # æ¯”è¾ƒè¯†åˆ«å™¨
    compare_recognizers(audio_data, sample_rate)
    
    logger.info("=" * 50)
    logger.info("ğŸ‰ éŸ³é¢‘å¢å¼ºåŠŸèƒ½æ¼”ç¤ºå®Œæˆ!")

if __name__ == "__main__":
    main()