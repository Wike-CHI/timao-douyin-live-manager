#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çœŸå®éŸ³é¢‘æ–‡ä»¶è½¬å½•æµ‹è¯•
æµ‹è¯•VOSKéŸ³é¢‘å¢å¼ºåŠŸèƒ½çš„å®é™…æ•ˆæœ

åŠŸèƒ½:
1. å¤„ç†çœŸå®çš„éŸ³é¢‘æ–‡ä»¶ (æ”¯æŒå¤šç§æ ¼å¼)
2. æµ‹è¯•éŸ³é¢‘å¢å¼ºåŠŸèƒ½çš„æ•ˆæœ
3. å¯¹æ¯”å¢å¼ºå‰åçš„è½¬å½•æ•ˆæœ
4. ç”Ÿæˆè¯¦ç»†çš„æµ‹è¯•æŠ¥å‘Š

ä¾èµ–:
pip install vosk numpy scipy pydub
"""

import sys
import os
import json
import time
import logging
from pathlib import Path
from typing import Dict, List, Optional, Tuple

# æ·»åŠ VOSKæ¨¡å—åˆ°è·¯å¾„
vosk_path = Path(__file__).parent / "vosk-api" / "python"
sys.path.insert(0, str(vosk_path))

try:
    import vosk
    from vosk import Model, KaldiRecognizer
    
    # å°è¯•å¯¼å…¥å¢å¼ºç‰ˆè¯†åˆ«å™¨
    EnhancedKaldiRecognizer = getattr(vosk, 'EnhancedKaldiRecognizer', None)
    ENHANCED_RECOGNIZER_AVAILABLE = EnhancedKaldiRecognizer is not None
    
    # å¯¼å…¥éŸ³é¢‘å¤„ç†åº“
    from pydub import AudioSegment
    from pydub.utils import which
    import numpy as np
    
    print("âœ… æ‰€æœ‰ä¾èµ–å¯¼å…¥æˆåŠŸ")
    
except ImportError as e:
    print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
    print("è¯·å®‰è£…æ‰€éœ€ä¾èµ–: pip install vosk numpy scipy pydub")
    print("æ³¨æ„: æ‚¨å¯èƒ½è¿˜éœ€è¦å®‰è£…ffmpegæ¥å¤„ç†éŸ³é¢‘æ–‡ä»¶")
    sys.exit(1)

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, 
                   format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class AudioTranscriptionTester:
    """éŸ³é¢‘è½¬å½•æµ‹è¯•å™¨"""
    
    def __init__(self, model_path: Optional[str] = None):
        """
        åˆå§‹åŒ–æµ‹è¯•å™¨
        
        Args:
            model_path: VOSKæ¨¡å‹è·¯å¾„
        """
        self.sample_rate = 16000
        self.chunk_size = 4000
        
        # è®¾ç½®VOSKæ—¥å¿—çº§åˆ«
        try:
            vosk.SetLogLevel(-1)
        except:
            pass
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.model = self._load_model(model_path)
        
        # åˆå§‹åŒ–è¯†åˆ«å™¨
        self.standard_recognizer = None
        self.enhanced_recognizer = None
        self._initialize_recognizers()
        
        # æµ‹è¯•ç»“æœ
        self.test_results = {
            "standard": {
                "transcription": "",
                "confidence": 0.0,
                "processing_time": 0.0,
                "word_count": 0
            },
            "enhanced": {
                "transcription": "",
                "confidence": 0.0,
                "processing_time": 0.0,
                "word_count": 0
            }
        }
    
    def _load_model(self, model_path: Optional[str]) -> Optional[object]:
        """åŠ è½½VOSKæ¨¡å‹"""
        logger.info("æ­£åœ¨åŠ è½½VOSKæ¨¡å‹...")
        
        try:
            if model_path and Path(model_path).exists():
                model = Model(model_path=model_path)
                logger.info(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {model_path}")
                return model
            else:
                # å°è¯•ä½¿ç”¨é»˜è®¤æ¨¡å‹
                logger.info("å°è¯•ä½¿ç”¨é»˜è®¤ä¸­æ–‡æ¨¡å‹...")
                model = Model(model_name="vosk-model-small-cn-0.22")
                logger.info("âœ… é»˜è®¤æ¨¡å‹åŠ è½½æˆåŠŸ")
                return model
                
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            logger.info("è¯·ç¡®ä¿å·²æ­£ç¡®å®‰è£…VOSKæ¨¡å‹")
            return None
    
    def _initialize_recognizers(self):
        """åˆå§‹åŒ–è¯†åˆ«å™¨"""
        if not self.model:
            logger.error("æ— æ³•åˆå§‹åŒ–è¯†åˆ«å™¨ï¼šæ¨¡å‹åŠ è½½å¤±è´¥")
            return
        
        try:
            # åˆå§‹åŒ–æ ‡å‡†è¯†åˆ«å™¨
            self.standard_recognizer = KaldiRecognizer(self.model, self.sample_rate)
            self.standard_recognizer.SetWords(True)
            logger.info("âœ… æ ‡å‡†è¯†åˆ«å™¨åˆå§‹åŒ–æˆåŠŸ")
            
            # å°è¯•åˆå§‹åŒ–å¢å¼ºç‰ˆè¯†åˆ«å™¨
            if ENHANCED_RECOGNIZER_AVAILABLE and EnhancedKaldiRecognizer is not None:
                self.enhanced_recognizer = EnhancedKaldiRecognizer(self.model, self.sample_rate)
                self.enhanced_recognizer.SetWords(True)
                logger.info("âœ… å¢å¼ºç‰ˆè¯†åˆ«å™¨åˆå§‹åŒ–æˆåŠŸ")
            else:
                logger.warning("âš ï¸ å¢å¼ºç‰ˆè¯†åˆ«å™¨ä¸å¯ç”¨ï¼Œå°†åªæµ‹è¯•æ ‡å‡†è¯†åˆ«å™¨")
                
        except Exception as e:
            logger.error(f"âŒ è¯†åˆ«å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
    
    def convert_audio_to_wav(self, audio_path: str) -> str:
        """
        å°†éŸ³é¢‘æ–‡ä»¶è½¬æ¢ä¸ºWAVæ ¼å¼
        
        Args:
            audio_path: è¾“å…¥éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            è½¬æ¢åçš„WAVæ–‡ä»¶è·¯å¾„
        """
        logger.info(f"æ­£åœ¨è½¬æ¢éŸ³é¢‘æ–‡ä»¶: {audio_path}")
        
        try:
            # åŠ è½½éŸ³é¢‘æ–‡ä»¶
            audio = AudioSegment.from_file(audio_path)
            
            # è½¬æ¢ä¸ºå•å£°é“ï¼Œ16kHzé‡‡æ ·ç‡
            audio = audio.set_channels(1)
            audio = audio.set_frame_rate(self.sample_rate)
            audio = audio.set_sample_width(2)  # 16-bit
            
            # å¯¼å‡ºä¸ºWAVæ ¼å¼
            output_path = Path(audio_path).parent / f"{Path(audio_path).stem}_converted.wav"
            audio.export(str(output_path), format="wav")
            
            logger.info(f"âœ… éŸ³é¢‘è½¬æ¢å®Œæˆ: {output_path}")
            return str(output_path)
            
        except Exception as e:
            logger.error(f"âŒ éŸ³é¢‘è½¬æ¢å¤±è´¥: {e}")
            raise
    
    def transcribe_audio(self, wav_path: str, use_enhanced: bool = False) -> Dict:
        """
        è½¬å½•éŸ³é¢‘æ–‡ä»¶
        
        Args:
            wav_path: WAVéŸ³é¢‘æ–‡ä»¶è·¯å¾„
            use_enhanced: æ˜¯å¦ä½¿ç”¨å¢å¼ºç‰ˆè¯†åˆ«å™¨
            
        Returns:
            è½¬å½•ç»“æœå­—å…¸
        """
        recognizer = self.enhanced_recognizer if use_enhanced else self.standard_recognizer
        
        if not recognizer:
            logger.error("è¯†åˆ«å™¨æœªåˆå§‹åŒ–")
            return {"transcription": "", "confidence": 0.0, "processing_time": 0.0}
        
        logger.info(f"å¼€å§‹è½¬å½•éŸ³é¢‘ ({'å¢å¼ºç‰ˆ' if use_enhanced else 'æ ‡å‡†ç‰ˆ'}è¯†åˆ«å™¨)")
        
        start_time = time.time()
        results = []
        
        try:
            with open(wav_path, 'rb') as audio_file:
                # è·³è¿‡WAVæ–‡ä»¶å¤´
                audio_file.seek(44)
                
                while True:
                    data = audio_file.read(self.chunk_size)
                    if len(data) == 0:
                        break
                    
                    if recognizer.AcceptWaveform(data):
                        result = json.loads(recognizer.Result())
                        if result.get('text', '').strip():
                            results.append(result)
                
                # è·å–æœ€ç»ˆç»“æœ
                final_result = json.loads(recognizer.FinalResult())
                if final_result.get('text', '').strip():
                    results.append(final_result)
        
        except Exception as e:
            logger.error(f"è½¬å½•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return {"transcription": "", "confidence": 0.0, "processing_time": 0.0}
        
        processing_time = time.time() - start_time
        
        # åˆå¹¶è½¬å½•ç»“æœ
        full_transcription = []
        total_confidence = 0.0
        word_count = 0
        
        for result in results:
            text = result.get('text', '').strip()
            if text:
                full_transcription.append(text)
                
                # è®¡ç®—å¹³å‡ç½®ä¿¡åº¦
                if 'result' in result and result['result']:
                    confidences = [word.get('conf', 0.0) for word in result['result']]
                    if confidences:
                        total_confidence += sum(confidences)
                        word_count += len(confidences)
        
        final_transcription = ' '.join(full_transcription)
        avg_confidence = total_confidence / word_count if word_count > 0 else 0.0
        
        logger.info(f"âœ… è½¬å½•å®Œæˆ ({processing_time:.2f}ç§’)")
        logger.info(f"è½¬å½•ç»“æœ: {final_transcription[:100]}{'...' if len(final_transcription) > 100 else ''}")
        
        return {
            "transcription": final_transcription,
            "confidence": avg_confidence,
            "processing_time": processing_time,
            "word_count": word_count
        }
    
    def test_audio_file(self, audio_path: str) -> Dict:
        """
        æµ‹è¯•éŸ³é¢‘æ–‡ä»¶è½¬å½•
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            æµ‹è¯•ç»“æœ
        """
        logger.info(f"å¼€å§‹æµ‹è¯•éŸ³é¢‘æ–‡ä»¶: {audio_path}")
        
        if not Path(audio_path).exists():
            logger.error(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
            return {}
        
        # è½¬æ¢éŸ³é¢‘æ ¼å¼
        try:
            wav_path = self.convert_audio_to_wav(audio_path)
        except Exception as e:
            logger.error(f"éŸ³é¢‘è½¬æ¢å¤±è´¥: {e}")
            return {}
        
        # æµ‹è¯•æ ‡å‡†è¯†åˆ«å™¨
        logger.info("\n" + "="*50)
        logger.info("ğŸ” æµ‹è¯•æ ‡å‡†è¯†åˆ«å™¨")
        logger.info("="*50)
        
        self.test_results["standard"] = self.transcribe_audio(wav_path, use_enhanced=False)
        
        # æµ‹è¯•å¢å¼ºç‰ˆè¯†åˆ«å™¨
        if self.enhanced_recognizer:
            logger.info("\n" + "="*50)
            logger.info("ğŸš€ æµ‹è¯•å¢å¼ºç‰ˆè¯†åˆ«å™¨")
            logger.info("="*50)
            
            self.test_results["enhanced"] = self.transcribe_audio(wav_path, use_enhanced=True)
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            Path(wav_path).unlink()
        except:
            pass
        
        return self.test_results
    
    def generate_report(self) -> str:
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        report = []
        report.append("ğŸ™ï¸ VOSKéŸ³é¢‘è½¬å½•æµ‹è¯•æŠ¥å‘Š")
        report.append("=" * 60)
        
        # æµ‹è¯•ç¯å¢ƒä¿¡æ¯
        report.append("\nğŸ“‹ æµ‹è¯•ç¯å¢ƒ:")
        report.append(f"  VOSKç‰ˆæœ¬: {'å·²å®‰è£…' if self.model else 'æœªå®‰è£…'}")
        report.append(f"  å¢å¼ºåŠŸèƒ½: {'å¯ç”¨' if ENHANCED_RECOGNIZER_AVAILABLE else 'ä¸å¯ç”¨'}")
        report.append(f"  é‡‡æ ·ç‡: {self.sample_rate}Hz")
        report.append(f"  å—å¤§å°: {self.chunk_size} bytes")
        
        # æ ‡å‡†è¯†åˆ«å™¨ç»“æœ
        std_result = self.test_results["standard"]
        report.append("\nğŸ” æ ‡å‡†è¯†åˆ«å™¨ç»“æœ:")
        report.append(f"  è½¬å½•æ–‡æœ¬: {std_result.get('transcription', 'N/A')}")
        report.append(f"  å¹³å‡ç½®ä¿¡åº¦: {std_result.get('confidence', 0):.3f}")
        report.append(f"  å¤„ç†æ—¶é—´: {std_result.get('processing_time', 0):.2f}ç§’")
        report.append(f"  è¯†åˆ«è¯æ•°: {std_result.get('word_count', 0)}")
        
        # å¢å¼ºç‰ˆè¯†åˆ«å™¨ç»“æœ
        if self.enhanced_recognizer:
            enh_result = self.test_results["enhanced"]
            report.append("\nğŸš€ å¢å¼ºç‰ˆè¯†åˆ«å™¨ç»“æœ:")
            report.append(f"  è½¬å½•æ–‡æœ¬: {enh_result.get('transcription', 'N/A')}")
            report.append(f"  å¹³å‡ç½®ä¿¡åº¦: {enh_result.get('confidence', 0):.3f}")
            report.append(f"  å¤„ç†æ—¶é—´: {enh_result.get('processing_time', 0):.2f}ç§’")
            report.append(f"  è¯†åˆ«è¯æ•°: {enh_result.get('word_count', 0)}")
            
            # æ€§èƒ½å¯¹æ¯”
            report.append("\nğŸ“Š æ€§èƒ½å¯¹æ¯”:")
            
            # ç½®ä¿¡åº¦æ”¹è¿›
            conf_improvement = enh_result.get('confidence', 0) - std_result.get('confidence', 0)
            report.append(f"  ç½®ä¿¡åº¦æ”¹è¿›: {conf_improvement:+.3f}")
            
            # å¤„ç†æ—¶é—´å¯¹æ¯”
            time_diff = enh_result.get('processing_time', 0) - std_result.get('processing_time', 0)
            report.append(f"  æ—¶é—´å·®å¼‚: {time_diff:+.2f}ç§’")
            
            # è¯æ•°å¯¹æ¯”
            word_diff = enh_result.get('word_count', 0) - std_result.get('word_count', 0)
            report.append(f"  è¯†åˆ«è¯æ•°å·®å¼‚: {word_diff:+d}")
            
            # æ–‡æœ¬ç›¸ä¼¼åº¦(ç®€å•å¯¹æ¯”)
            std_text = std_result.get('transcription', '')
            enh_text = enh_result.get('transcription', '')
            if std_text and enh_text:
                similarity = len(set(std_text.split()) & set(enh_text.split())) / max(len(std_text.split()), len(enh_text.split())) * 100
                report.append(f"  æ–‡æœ¬ç›¸ä¼¼åº¦: {similarity:.1f}%")
        
        report.append("\n" + "=" * 60)
        return "\n".join(report)
    
    def save_report(self, filepath: str):
        """ä¿å­˜æµ‹è¯•æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        report = self.generate_report()
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(report)
        logger.info(f"ğŸ“„ æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜: {filepath}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ™ï¸ VOSKéŸ³é¢‘è½¬å½•çœŸå®æµ‹è¯•")
    print("=" * 50)
    
    # æŸ¥æ‰¾æµ‹è¯•éŸ³é¢‘æ–‡ä»¶
    test_audio_path = Path(__file__).parent / "tests" / "å½•éŸ³ (12).m4a"
    
    if not test_audio_path.exists():
        print(f"âŒ æ‰¾ä¸åˆ°æµ‹è¯•éŸ³é¢‘æ–‡ä»¶: {test_audio_path}")
        print("è¯·ç¡®ä¿testsæ–‡ä»¶å¤¹ä¸­æœ‰éŸ³é¢‘æ–‡ä»¶")
        return
    
    print(f"ğŸ“ æµ‹è¯•éŸ³é¢‘æ–‡ä»¶: {test_audio_path}")
    
    # åˆ›å»ºæµ‹è¯•å™¨
    try:
        tester = AudioTranscriptionTester()
        
        # æ‰§è¡Œæµ‹è¯•
        results = tester.test_audio_file(str(test_audio_path))
        
        if results:
            # æ˜¾ç¤ºæŠ¥å‘Š
            report = tester.generate_report()
            print("\n" + report)
            
            # ä¿å­˜æŠ¥å‘Š
            report_path = Path(__file__).parent / "audio_transcription_test_report.txt"
            tester.save_report(str(report_path))
            
            print(f"\nâœ… æµ‹è¯•å®Œæˆï¼æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_path}")
        else:
            print("âŒ æµ‹è¯•å¤±è´¥")
            
    except Exception as e:
        logger.error(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        print("âŒ æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯æ—¥å¿—")


if __name__ == "__main__":
    main()