#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é•¿éŸ³é¢‘å®æ—¶å¤„ç†æµ‹è¯•è„šæœ¬
ç”¨äºæµ‹è¯•30åˆ†é’Ÿæ¼”è®²éŸ³é¢‘çš„å¤„ç†æ€§èƒ½
"""

import sys
import os
import time
import json
import logging
import numpy as np
from pathlib import Path
from pydub import AudioSegment
from typing import Tuple, Union

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_path = Path(__file__).parent
sys.path.insert(0, str(project_path))

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

try:
    import vosk
    from audio_enhancer import AudioEnhancer, EnhancedKaldiRecognizer
    logger.info("âœ… æˆåŠŸå¯¼å…¥æ‰€éœ€æ¨¡å—")
except ImportError as e:
    logger.error(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    sys.exit(1)

def load_test_audio(audio_path: str) -> tuple:
    """åŠ è½½å¹¶è½¬æ¢æµ‹è¯•éŸ³é¢‘"""
    logger.info("ğŸ”„ åŠ è½½æµ‹è¯•éŸ³é¢‘...")
    
    try:
        # åŠ è½½éŸ³é¢‘
        audio = AudioSegment.from_file(audio_path)
        logger.info(f"   åŸå§‹éŸ³é¢‘: {audio.frame_rate}Hz, {audio.channels}å£°é“, {len(audio)/1000:.2f}ç§’")
        
        # è½¬æ¢ä¸ºå•å£°é“16kHz
        if audio.channels > 1:
            audio = audio.set_channels(1)
        if audio.frame_rate != 16000:
            audio = audio.set_frame_rate(16000)
        audio = audio.set_sample_width(2)  # 16-bit
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        samples = np.array(audio.get_array_of_samples())
        logger.info(f"   è½¬æ¢åéŸ³é¢‘: {len(samples)} é‡‡æ ·ç‚¹")
        
        return samples, audio.frame_rate
    except Exception as e:
        logger.error(f"âŒ éŸ³é¢‘åŠ è½½å¤±è´¥: {e}")
        return None, None

def process_audio_with_timing(audio_data: np.ndarray, sample_rate: int, use_enhancement: bool = False) -> Tuple[str, int, float]:
    """å¤„ç†éŸ³é¢‘å¹¶è®¡æ—¶"""
    logger.info(f"ğŸš€ å¼€å§‹å¤„ç†éŸ³é¢‘ (å¢å¼º: {'å¼€å¯' if use_enhancement else 'å…³é—­'})")
    
    # åˆå§‹åŒ–æ¨¡å‹
    logger.info("   åŠ è½½VOSKæ¨¡å‹...")
    model = vosk.Model(model_name="vosk-model-small-cn-0.22")
    
    # åˆ›å»ºè¯†åˆ«å™¨
    base_recognizer = vosk.KaldiRecognizer(model, sample_rate)
    base_recognizer.SetWords(True)
    
    # ç±»å‹æ³¨è§£å¸®åŠ©é™æ€åˆ†æå·¥å…·ç†è§£
    recognizer: Union[vosk.KaldiRecognizer, EnhancedKaldiRecognizer]
    
    if use_enhancement:
        recognizer = EnhancedKaldiRecognizer(
            base_recognizer,
            enable_audio_enhancement=True,
            noise_reduction_strength=0.5,
            gain_target=0.7
        )
        # ç±»å‹å®‰å…¨æ£€æŸ¥
        if isinstance(recognizer, EnhancedKaldiRecognizer):
            recognizer.EnableAudioEnhancement(True)
        logger.info("   å·²å¯ç”¨éŸ³é¢‘å¢å¼ºåŠŸèƒ½")
    else:
        recognizer = base_recognizer
        logger.info("   ä½¿ç”¨æ ‡å‡†è¯†åˆ«å™¨")
    
    start_time = time.time()
    results = []
    
    # åˆ†å—å¤„ç†éŸ³é¢‘ï¼ˆæ¨¡æ‹Ÿå®æ—¶æµï¼‰
    chunk_size = 4000  # 4000 bytes â‰ˆ 0.25ç§’ (16kHz, 16-bit)
    chunk_samples = chunk_size // 2
    
    total_samples = len(audio_data)
    processed_samples = 0
    
    # è¿›åº¦è·Ÿè¸ª
    last_progress = 0
    logger.info("   å¼€å§‹å¤„ç†éŸ³é¢‘æ•°æ®...")
    
    while processed_samples < total_samples:
        chunk_end = min(processed_samples + chunk_samples, total_samples)
        chunk = audio_data[processed_samples:chunk_end]
        chunk_bytes = chunk.tobytes()
        
        if recognizer.AcceptWaveform(chunk_bytes):
            result = json.loads(recognizer.Result())
            if result.get('text', '').strip():
                results.append(result)
        
        processed_samples = chunk_end
        
        # æ˜¾ç¤ºè¿›åº¦
        progress = int((processed_samples / total_samples) * 100)
        if progress >= last_progress + 10:  # æ¯10%æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
            elapsed = time.time() - start_time
            logger.info(f"   å¤„ç†è¿›åº¦: {progress}% (å·²ç”¨æ—¶: {elapsed:.1f}ç§’)")
            last_progress = progress
    
    # è·å–æœ€ç»ˆç»“æœ
    final_result = json.loads(recognizer.FinalResult())
    if final_result.get('text', '').strip():
        results.append(final_result)
    
    total_time = time.time() - start_time
    
    # åˆå¹¶ç»“æœ
    full_text = ' '.join([r.get('text', '') for r in results if r.get('text', '').strip()])
    word_count = sum([len(r.get('result', [])) for r in results])
    
    logger.info(f"   è¯†åˆ«å®Œæˆ!")
    logger.info(f"   è¯†åˆ«æ–‡æœ¬: {full_text[:100]}{'...' if len(full_text) > 100 else ''}")
    logger.info(f"   è¯†åˆ«è¯æ•°: {word_count}")
    logger.info(f"   å¤„ç†æ—¶é—´: {total_time:.2f}ç§’")
    
    # å¦‚æœä½¿ç”¨å¢å¼ºï¼Œæ˜¾ç¤ºå¢å¼ºç»Ÿè®¡
    if use_enhancement and isinstance(recognizer, EnhancedKaldiRecognizer):
        enhancement_stats = recognizer.GetEnhancementStats()
        logger.info(f"   å¢å¼ºå¤„ç†å—æ•°: {enhancement_stats.get('processed_chunks', 0)}")
        logger.info(f"   å¹³å‡å¢å¼ºæ—¶é—´: {enhancement_stats.get('average_enhancement_time', 0)*1000:.2f}æ¯«ç§’")
    
    return full_text, word_count, total_time

def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸ™ï¸ é•¿éŸ³é¢‘å®æ—¶å¤„ç†æµ‹è¯•")
    logger.info("=" * 50)
    
    # æŒ‡å®šæµ‹è¯•éŸ³é¢‘æ–‡ä»¶è·¯å¾„ (ä¿®æ”¹ä¸ºç”¨æˆ·æŒ‡å®šçš„æ–‡ä»¶)
    test_audio_path = project_path / "tests" / "27994754259-1-30280.mp4"
    
    if not test_audio_path.exists():
        logger.error(f"âŒ æ‰¾ä¸åˆ°æµ‹è¯•éŸ³é¢‘æ–‡ä»¶: {test_audio_path}")
        return
    
    logger.info(f"ğŸ“ ä½¿ç”¨æµ‹è¯•éŸ³é¢‘: {test_audio_path}")
    
    # æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼ˆé¢„ä¼°æ—¶é•¿ï¼‰
    file_size_mb = test_audio_path.stat().st_size / (1024 * 1024)
    logger.info(f"   æ–‡ä»¶å¤§å°: {file_size_mb:.1f} MB")
    
    # åŠ è½½éŸ³é¢‘
    audio_data, sample_rate = load_test_audio(str(test_audio_path))
    if audio_data is None:
        return
    
    # ä¼°ç®—éŸ³é¢‘æ—¶é•¿
    estimated_duration = len(audio_data) / sample_rate
    logger.info(f"   ä¼°ç®—æ—¶é•¿: {estimated_duration/60:.1f} åˆ†é’Ÿ")
    
    # æµ‹è¯•1: æ ‡å‡†å¤„ç†
    logger.info("\n" + "=" * 50)
    standard_text, standard_words, standard_time = process_audio_with_timing(
        audio_data, sample_rate, use_enhancement=False
    )
    
    # æµ‹è¯•2: å¢å¼ºå¤„ç†
    logger.info("\n" + "=" * 50)
    enhanced_text, enhanced_words, enhanced_time = process_audio_with_timing(
        audio_data, sample_rate, use_enhancement=True
    )
    
    # è¾“å‡ºæ¯”è¾ƒç»“æœ
    logger.info("\n" + "=" * 50)
    logger.info("ğŸ“Š æ€§èƒ½æ¯”è¾ƒç»“æœ:")
    logger.info(f"   éŸ³é¢‘æ—¶é•¿: {estimated_duration/60:.1f} åˆ†é’Ÿ")
    logger.info(f"   æ ‡å‡†å¤„ç†: {standard_time:.1f}ç§’ ({standard_time/estimated_duration*1000:.1f}å€é€Ÿ)")
    logger.info(f"   å¢å¼ºå¤„ç†: {enhanced_time:.1f}ç§’ ({enhanced_time/estimated_duration*1000:.1f}å€é€Ÿ)")
    logger.info(f"   å¤„ç†å·®å¼‚: {enhanced_time - standard_time:+.1f}ç§’")
    logger.info(f"   è¯æ•°å¯¹æ¯”: æ ‡å‡†={standard_words}, å¢å¼º={enhanced_words}")
    
    # ä¿å­˜ç»“æœ
    results_dir = project_path / "test_results"
    results_dir.mkdir(exist_ok=True)
    
    # ä¿å­˜æ–‡æœ¬ç»“æœ
    with open(results_dir / "standard_transcription.txt", "w", encoding="utf-8") as f:
        f.write(standard_text)
    
    with open(results_dir / "enhanced_transcription.txt", "w", encoding="utf-8") as f:
        f.write(enhanced_text)
    
    logger.info(f"\nğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {results_dir}")
    logger.info("ğŸ‰ é•¿éŸ³é¢‘å¤„ç†æµ‹è¯•å®Œæˆ!")

if __name__ == "__main__":
    main()