#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€åŒ–ç‰ˆé•¿éŸ³é¢‘æµ‹è¯•è„šæœ¬
ä¸“é—¨ç”¨äºæµ‹è¯•30åˆ†é’Ÿæ¼”è®²éŸ³é¢‘çš„å¤„ç†æ€§èƒ½
"""

import sys
import os
import time
import json
import logging
import numpy as np
from pathlib import Path
from pydub import AudioSegment

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_path = Path(__file__).parent
sys.path.insert(0, str(project_path))

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

try:
    import vosk
    logger.info("âœ… æˆåŠŸå¯¼å…¥VOSKæ¨¡å—")
except ImportError as e:
    logger.error(f"âŒ å¯¼å…¥VOSKæ¨¡å—å¤±è´¥: {e}")
    sys.exit(1)

def load_test_audio(audio_path: str) -> tuple:
    """åŠ è½½å¹¶è½¬æ¢æµ‹è¯•éŸ³é¢‘"""
    logger.info("ğŸ”„ åŠ è½½æµ‹è¯•éŸ³é¢‘...")
    
    try:
        # åŠ è½½éŸ³é¢‘
        audio = AudioSegment.from_file(audio_path)
        logger.info(f"   åŸå§‹éŸ³é¢‘: {audio.frame_rate}Hz, {audio.channels}å£°é“, {len(audio)/1000:.2f}ç§’")
        
        # è½¬æ¢ä¸ºå•å£°é“16kHz
        if audio.channels > 1:
            audio = audio.set_channels(1)
        if audio.frame_rate != 16000:
            audio = audio.set_frame_rate(16000)
        audio = audio.set_sample_width(2)  # 16-bit
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        samples = np.array(audio.get_array_of_samples())
        logger.info(f"   è½¬æ¢åéŸ³é¢‘: {len(samples)} é‡‡æ ·ç‚¹")
        
        return samples, audio.frame_rate
    except Exception as e:
        logger.error(f"âŒ éŸ³é¢‘åŠ è½½å¤±è´¥: {e}")
        return None, None

def process_audio_simple(audio_data: np.ndarray, sample_rate: int) -> tuple:
    """ç®€å•å¤„ç†éŸ³é¢‘"""
    logger.info("ğŸš€ å¼€å§‹å¤„ç†éŸ³é¢‘...")
    
    # åˆå§‹åŒ–æ¨¡å‹
    logger.info("   åŠ è½½VOSKæ¨¡å‹...")
    model = vosk.Model(model_name="vosk-model-small-cn-0.22")
    
    # åˆ›å»ºè¯†åˆ«å™¨
    recognizer = vosk.KaldiRecognizer(model, sample_rate)
    recognizer.SetWords(True)
    
    start_time = time.time()
    results = []
    
    # åˆ†å—å¤„ç†éŸ³é¢‘ï¼ˆæ¨¡æ‹Ÿå®æ—¶æµï¼‰
    chunk_size = 4000  # 4000 bytes â‰ˆ 0.25ç§’ (16kHz, 16-bit)
    chunk_samples = chunk_size // 2
    
    total_samples = len(audio_data)
    processed_samples = 0
    
    # è¿›åº¦è·Ÿè¸ª
    last_progress = 0
    logger.info("   å¼€å§‹å¤„ç†éŸ³é¢‘æ•°æ®...")
    
    while processed_samples < total_samples:
        chunk_end = min(processed_samples + chunk_samples, total_samples)
        chunk = audio_data[processed_samples:chunk_end]
        chunk_bytes = chunk.tobytes()
        
        if recognizer.AcceptWaveform(chunk_bytes):
            result = json.loads(recognizer.Result())
            if result.get('text', '').strip():
                results.append(result)
        
        processed_samples = chunk_end
        
        # æ˜¾ç¤ºè¿›åº¦ï¼ˆæ¯5%æ˜¾ç¤ºä¸€æ¬¡ï¼‰
        progress = int((processed_samples / total_samples) * 100)
        if progress >= last_progress + 5:
            elapsed = time.time() - start_time
            logger.info(f"   å¤„ç†è¿›åº¦: {progress}% (å·²ç”¨æ—¶: {elapsed:.1f}ç§’)")
            last_progress = progress
    
    # è·å–æœ€ç»ˆç»“æœ
    final_result = json.loads(recognizer.FinalResult())
    if final_result.get('text', '').strip():
        results.append(final_result)
    
    total_time = time.time() - start_time
    
    # åˆå¹¶ç»“æœ
    full_text = ' '.join([r.get('text', '') for r in results if r.get('text', '').strip()])
    word_count = sum([len(r.get('result', [])) for r in results])
    
    logger.info(f"   è¯†åˆ«å®Œæˆ!")
    logger.info(f"   è¯†åˆ«è¯æ•°: {word_count}")
    logger.info(f"   å¤„ç†æ—¶é—´: {total_time:.2f}ç§’")
    
    return full_text, word_count, total_time

def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸ™ï¸ ç®€åŒ–ç‰ˆé•¿éŸ³é¢‘å¤„ç†æµ‹è¯•")
    logger.info("=" * 50)
    
    # æŒ‡å®šæµ‹è¯•éŸ³é¢‘æ–‡ä»¶è·¯å¾„
    test_audio_path = project_path / "tests" / "30198727526-1-30216.mp4"
    
    if not test_audio_path.exists():
        logger.error(f"âŒ æ‰¾ä¸åˆ°æµ‹è¯•éŸ³é¢‘æ–‡ä»¶: {test_audio_path}")
        return
    
    logger.info(f"ğŸ“ ä½¿ç”¨æµ‹è¯•éŸ³é¢‘: {test_audio_path}")
    
    # æ£€æŸ¥æ–‡ä»¶å¤§å°
    file_size_mb = test_audio_path.stat().st_size / (1024 * 1024)
    logger.info(f"   æ–‡ä»¶å¤§å°: {file_size_mb:.1f} MB")
    
    # åŠ è½½éŸ³é¢‘
    audio_data, sample_rate = load_test_audio(str(test_audio_path))
    if audio_data is None:
        return
    
    # ä¼°ç®—éŸ³é¢‘æ—¶é•¿
    estimated_duration = len(audio_data) / sample_rate
    logger.info(f"   ä¼°ç®—æ—¶é•¿: {estimated_duration/60:.1f} åˆ†é’Ÿ")
    
    # å¤„ç†éŸ³é¢‘
    logger.info("\n" + "=" * 50)
    text, words, process_time = process_audio_simple(audio_data, sample_rate)
    
    # ä¿å­˜ç»“æœ
    results_dir = project_path / "test_results"
    results_dir.mkdir(exist_ok=True)
    
    with open(results_dir / "simple_transcription.txt", "w", encoding="utf-8") as f:
        f.write(text)
    
    logger.info(f"\nğŸ“ è½¬å½•æ–‡æœ¬å·²ä¿å­˜åˆ°: {results_dir / 'simple_transcription.txt'}")
    logger.info("ğŸ‰ é•¿éŸ³é¢‘å¤„ç†æµ‹è¯•å®Œæˆ!")

if __name__ == "__main__":
    main()