# AST语音转录算法优化需求对齐文档

## 📋 项目特性规范

### 核心需求

- **目标用户**: 主播（直播场景下的语音识别）
- **性能要求**: 语音识别准确率需大于80%（符合MVP标准）
- **数据要求**: 必须使用真实的测试集成结果，不允许使用模拟数据
- **使用场景**: 长时间（3-8小时）连续直播语音转录

### 当前系统分析

#### 技术架构现状

1. **VOSK模型**: vosk-model-cn-0.22（2.04GB中文模型）
2. **置信度计算**: 当前使用简单平均算法
3. **音频处理**: 16kHz采样率，1024字节块大小
4. **最小置信度阈值**: 默认0.5（偏低，可能产生噪音识别）

#### 性能指标现状

- **模型基准性能**:
  - SpeechIO_02: 13.98% CER
  - SpeechIO_06: 27.30% CER
  - THCHS: 7.43% CER
- **当前置信度计算**: 简单词级平均
- **音频块处理**: 1秒固定时长

## 🎯 优化目标

### 主要优化方向

1. **置信度算法优化**

   - 当前: 简单平均 `sum(confidences) / len(confidences)`
   - 目标: 考虑词频、语言模型、上下文的智能置信度
2. **音频预处理增强**

   - 降噪算法集成
   - 音量归一化
   - 静音检测优化
3. **主播场景特化**

   - 直播常用词汇优化
   - 网络流行语识别
   - 产品介绍词汇增强
4. **动态参数调优**

   - 自适应置信度阈值
   - 智能音频块大小调整
   - 上下文相关的后处理

## 🤔 需求澄清

### 疑问点需要确认

1. **优化范围边界**

   - 是否需要训练新的声学模型？不需要
   - 是否可以集成外部语言模型（如GPT-based后处理）？不需要
   - 是否需要支持多方言识别（如粤语、东北话）？不需要
2. **性能与资源平衡**

   - 可接受的额外计算资源消耗？可接受
   - 实时性要求（延迟容忍度）？最好是5秒-10秒
   - 内存使用限制？不受限制
3. **主播特定需求**

   - 是否需要特定领域词汇（美妆、游戏、教育等）？情感博主
   - 是否需要情感语调识别？需要
   - 是否需要多人对话区分？不需要
4. **数据和隐私**

   - 是否可以收集主播语音数据用于优化？不需要
   - 是否需要离线模式（无网络环境）？就是离线模式
   - 语音数据本地化处理要求？需要

## 📊 验收标准

### 可量化指标

- **准确率提升**: 从当前水平提升至>80%
- **置信度相关性**: 置信度与实际准确率相关系数>0.8
- **实时性保持**: 平均识别延迟<500ms
- **稳定性**: 连续运行3小时无性能衰减

### 可测试场景

- **标准普通话**: 新闻播报风格语音
- **网络用语**: 包含流行词汇的直播语音
- **产品介绍**: 商品描述、价格、特性介绍
- **互动对话**: 与观众问答式对话
- **噪音环境**: 有背景音乐的直播环境

## 🚧 技术约束

### 必须遵循的限制

- **真实数据**: 不使用模拟数据进行测试
- **现有架构**: 基于VOSK模型进行优化，不替换核心引擎
- **兼容性**: 保持与现有AST_module接口兼容
- **资源限制**: 在现有硬件条件下运行（4GB RAM）

### 关键假设需确认

- VOSK模型不可更换（使用vosk-model-cn-0.22）
- 主要优化音频预处理和后处理算法
- 保持Python生态系统集成
- 支持Windows环境部署
